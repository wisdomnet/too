{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wisdomnet/too/blob/master/built_step_by_step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5r9ifIJHz3m",
        "outputId": "8dfd5be4-a14e-4611-de4b-2a6e529ff52c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "os.chdir('./NNToyFramework/python-neural-networks/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgONVbfQPtfp"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdNuhyJTP-Tc"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self, input_shape=None, output_shape=None, trainable=True):\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = output_shape\n",
        "        self.trainable = trainable\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "        \n",
        "\n",
        "    def on_input_shape(self):\n",
        "        pass\n",
        "\n",
        "    def initialize(self, initializer):\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, output_gradient):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward_batch(self, input, batch_size):\n",
        "        batch_output=[]\n",
        "        for i in range(batch_size):\n",
        "            batch_output.append(self.forward(input[i]))\n",
        "        self.input = input\n",
        "        self.output = np.array(batch_output)         \n",
        "        return self.output   \n",
        "\n",
        "    def backward_b(self, output_gradient, input_layer, output_layer):\n",
        "        raise NotImplementedError \n",
        "    \n",
        "    def backward_batch(self, output_gradient, batch_size):\n",
        "        batch_first=[]\n",
        "        batch_second=[]\n",
        "        for i in range(batch_size):\n",
        "            first, second =self.backward_b(output_gradient=output_gradient[i],\n",
        "                                           input_layer=self.input[i],\n",
        "                                           output_layer=self.output[i])\n",
        "            batch_first.append(first)\n",
        "            batch_second.append(second)\n",
        "        return batch_first,batch_second\n",
        "\n",
        "    def update(self, updates):\n",
        "        if self.trainable:\n",
        "            raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm6R73c9QAFh"
      },
      "outputs": [],
      "source": [
        "#Reshape((1, 784), input_shape=(28, 28))\n",
        "class Reshape(Layer):\n",
        "    def __init__(self, output_shape, **kwargs):\n",
        "        super().__init__(output_shape=output_shape, trainable=False, **kwargs)\n",
        "\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return np.reshape(input, self.output_shape)\n",
        "    \n",
        "    def backward(self, output_gradient):\n",
        "        return np.reshape(output_gradient, self.input_shape), None\n",
        "    \n",
        "    def backward_b(self, output_gradient, input_layer, output_layer):\n",
        "        return np.reshape(output_gradient, self.input_shape), None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXMlG0mgPxR3"
      },
      "outputs": [],
      "source": [
        "#Dense(50)\n",
        "class Dense(Layer):\n",
        "    def __init__(self, output_size, **kwargs):\n",
        "        super().__init__(output_shape=(1, output_size), **kwargs)\n",
        "\n",
        "    def initialize(self, initializer):\n",
        "        input_size, output_size = self.input_shape[1], self.output_shape[1]\n",
        "        self.weights = initializer.get(input_size, output_size)\n",
        "        self.bias = initializer.get(1, output_size)\n",
        "        return [(input_size, output_size), (1, output_size)]\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [self.weights,self.bias]   \n",
        "    def set_weights(self,weights):\n",
        "        self.weights=weights[0]\n",
        "        self.bias=weights[1]\n",
        "        \n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return np.dot(input, self.weights) + self.bias\n",
        "    \n",
        "    \n",
        "\n",
        "    def backward(self, output_gradient):\n",
        "        return np.dot(output_gradient, self.weights.T), [\n",
        "            np.dot(self.input.T, output_gradient),\n",
        "            output_gradient\n",
        "        ]\n",
        "\n",
        "    def backward_b(self, output_gradient, input_layer, output_layer):\n",
        "        return np.dot(output_gradient, self.weights.T), [\n",
        "            np.dot( input_layer.T  , output_gradient),\n",
        "            output_gradient\n",
        "        ]    \n",
        "    \n",
        "\n",
        "    def update(self, updates):\n",
        "        \n",
        "        check=True\n",
        "        if(np.isnan(np.sum(updates[0]))):\n",
        "            print('backward update[0]:nan')\n",
        "            check=False\n",
        "            \n",
        "            \n",
        "        if(np.isnan(np.sum(updates[1]))):\n",
        "            print('backward update[1]:nan')\n",
        "            check=False\n",
        "        if(np.isnan(np.sum(self.weights))):\n",
        "            print('backward self.weights:nan')\n",
        "            check=False\n",
        "        if(np.isnan(np.sum(self.bias))):\n",
        "            print('backward self.bias:nan')\n",
        "            check=False\n",
        "        \n",
        "        self.weights += updates[0]\n",
        "        self.bias += updates[1]\n",
        "        \n",
        "        if(np.isnan(np.sum(self.weights))):\n",
        "            print('backward self.weights:nan')\n",
        "            check=False\n",
        "        if(np.isnan(np.sum(self.bias))):\n",
        "            print('backward self.bias:nan')\n",
        "            check=False\n",
        "        return check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ13qA5yQP7C"
      },
      "outputs": [],
      "source": [
        "class BatchNormalization(Layer):\n",
        "    def __init__(self, epsilon=0.001, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def initialize(self, initializer):\n",
        "        self.gamma = initializer.get()\n",
        "        self.beta = initializer.get()\n",
        "        return [(1), (1)]\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.mu = np.mean(input)\n",
        "        self.sigma2 = np.var(input)\n",
        "        self.x_hat = (input - self.mu) / np.sqrt(self.sigma2 + self.epsilon)\n",
        "        return self.gamma * self.x_hat + self.beta\n",
        "\n",
        "    def forward_batch(self, input, batch_size):\n",
        "        self.input = input\n",
        "        self.mu = np.mean(input)\n",
        "        self.sigma2 = np.var(input)\n",
        "        self.x_hat = (input - self.mu) / np.sqrt(self.sigma2 + self.epsilon)\n",
        "        return self.gamma * self.x_hat + self.beta\n",
        "\n",
        "    def backward(self, output_gradient):\n",
        "        N = self.input.size\n",
        "        dx_hat = output_gradient * self.gamma\n",
        "        tmp = N * np.sqrt(self.sigma2 + self.epsilon)\n",
        "        input_gradient = (N * dx_hat - np.sum(dx_hat, axis=0) - self.x_hat * np.sum(dx_hat * self.x_hat, axis=0)) / tmp\n",
        "        return input_gradient, [\n",
        "            np.sum(output_gradient * self.x_hat, axis=0),\n",
        "            np.sum(output_gradient, axis=0)\n",
        "        ]\n",
        "\n",
        "    def update(self, updates):\n",
        "        self.gamma += updates[0]\n",
        "        self.beta += updates[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f95VbSlVQtwF"
      },
      "outputs": [],
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_prime, **kwargs):\n",
        "        super().__init__(trainable=False, **kwargs)\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(input)\n",
        "        \n",
        "    def backward(self, output_gradient):\n",
        "        return output_gradient * self.activation_prime(self.input), None\n",
        "\n",
        "    def backward_b(self, output_gradient, input_layer, output_layer):\n",
        "        return output_gradient * self.activation_prime(input_layer), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuRqgBBIQcYH"
      },
      "outputs": [],
      "source": [
        "class Softmax(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(trainable=False, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        return self.output\n",
        "   \n",
        "    def backward(self, output_error): \n",
        "        input_error = np.zeros(output_error.shape)    \n",
        "        out = np.tile(self.output.T, output_error.size)\n",
        "        return self.output * np.dot(output_error, np.identity(output_error.size) - out), None\n",
        "\n",
        "    \n",
        "    def backward_b(self, output_gradient, input_layer, output_layer):\n",
        "        input_error = np.zeros(output_gradient.shape)   \n",
        "        out = np.tile(output_layer.T, output_gradient.size)   \n",
        "        return output_layer * np.dot(output_gradient, np.identity(output_gradient.size) - out), None\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YcNPT9sQj2Z"
      },
      "outputs": [],
      "source": [
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.power(np.tanh(x), 2)\n",
        "\n",
        "class Tanh(Activation):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(tanh, tanh_prime, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDVPM1STQ7j3"
      },
      "outputs": [],
      "source": [
        "class Loss:\n",
        "    def call(self, y_true, y_pred):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def prime(self, y_true, y_pred):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class MSE(Loss):\n",
        "    def call(self, y_pred, y_true):\n",
        "        return np.mean(np.power(y_true - y_pred, 2))\n",
        "    \n",
        "    def call_batch(self, y_pred, y_true, batch_size):\n",
        "        batch_result=[]\n",
        "        for i in range(batch_size):\n",
        "            batch_result.append(self.call(y_pred[i],y_true[i]))\n",
        "        batch_result=np.array(batch_result)\n",
        "        return np.mean(batch_result)\n",
        "\n",
        "    def prime(self, y_true, y_pred):\n",
        "        check_prime=2 * (y_pred - y_true) / y_pred.size\n",
        "        if(np.isnan(np.sum(check_prime))):\n",
        "            print('fuck prime')\n",
        "        return check_prime\n",
        "    \n",
        "    def prime_batch(self, y_true, y_pred, batch_size):\n",
        "        batch_result=[]\n",
        "        for i in range(batch_size):\n",
        "            batch_result.append(self.prime(y_true[i],y_pred[i]))\n",
        "        batch_result=np.array(batch_result)\n",
        "        return batch_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg-EGcpvRN_f"
      },
      "outputs": [],
      "source": [
        "class OptimizerBase:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.gradients = []\n",
        "        self.shape = kwargs['shape']\n",
        "    \n",
        "    def set_gradients(self, gradients):\n",
        "        self.gradients.append(gradients)\n",
        "        #print(len(self.gradients))\n",
        "        #print(len(self.gradients[0].shape))\n",
        "        \n",
        "    \n",
        "    def get_gradients(self, iteration):\n",
        "        updated_gradients = self.update(iteration, np.sum(self.gradients, axis=0))\n",
        "        self.gradients = []\n",
        "        return updated_gradients\n",
        "\n",
        "    def update(self, iteration, gradients):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, OptimizerBaseClass, optimizerArgs, param_shapes):\n",
        "        self.optimizers = [\n",
        "            OptimizerBaseClass(**{**optimizerArgs, 'shape': shape})\n",
        "            for shape in param_shapes\n",
        "        ]\n",
        "\n",
        "    def set_gradients(self, gradients):\n",
        "        for optimizer, grad in zip(self.optimizers, gradients):\n",
        "            optimizer.set_gradients(grad)\n",
        "    '''\n",
        "    def set_gradients_batch(self, gradients):\n",
        "        for optimizer, grad in zip(self.optimizers, gradients):\n",
        "            optimizer.set_gradients_batch(grad)\n",
        "    '''\n",
        "\n",
        "    def set_gradients_batch(self, gradients, batch_size):\n",
        "        for i in range(batch_size):\n",
        "            self.set_gradients(gradients[i])\n",
        "\n",
        "\n",
        "    def get_gradients(self, iteration):\n",
        "        return [opt.get_gradients(iteration) for opt in self.optimizers]\n",
        "\n",
        "class SGD(OptimizerBase):\n",
        "    def __init__(self, learning_rate=0.01, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def update(self, iteration, weights):\n",
        "        return -self.learning_rate * weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU-MoKr8RxSj"
      },
      "outputs": [],
      "source": [
        "class Initializer:\n",
        "    def __init__(self):\n",
        "        self.layer_shapes = None\n",
        "        self.index = None\n",
        "\n",
        "    def set_layer_shapes(self, layer_shapes):\n",
        "        self.layer_shapes = layer_shapes\n",
        "\n",
        "    def set_layer_index(self, index):\n",
        "        self.index = index\n",
        "\n",
        "    def get_io_shape(self):\n",
        "        return self.layer_shapes[self.index]\n",
        "\n",
        "    def get(self):\n",
        "        return self.get(1)[0]\n",
        "\n",
        "    def get(self, *shape):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Xavier(Initializer):\n",
        "    def get(self, *shape):\n",
        "        io = self.get_io_shape()\n",
        "        input_neurons = np.prod(io[0])\n",
        "        return np.random.randn(*shape) * np.sqrt(1 / input_neurons)\n",
        "class Normal(Initializer):\n",
        "    def __init__(self, mean=0, std=1):\n",
        "        super().__init__()\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def get(self, *shape):\n",
        "        return np.random.normal(self.mean, self.std, shape)\n",
        "class Constant(Initializer):\n",
        "    def __init__(self, fill_value=1.0):\n",
        "        super().__init__()\n",
        "        self.fill_value = fill_value\n",
        "\n",
        "    def get(self, *shape):\n",
        "        return np.full(shape, self.fill_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScgHYFxJSDUB"
      },
      "outputs": [],
      "source": [
        "def create_model(network, initializer, OptimizerBaseClass, optimizerArgs={}):\n",
        "    print(len(network))\n",
        "\n",
        "    \n",
        "    for i, layer in enumerate(network):\n",
        "        print(i,layer.input_shape,layer.output_shape)\n",
        "    print('----')\n",
        "    \n",
        "\n",
        "    # set input_shape & output_shape\n",
        "    for i, layer in enumerate(network):\n",
        "        #print(i,'layer')\n",
        "        if not layer.input_shape:\n",
        "            layer.input_shape = network[i - 1].output_shape\n",
        "        layer.on_input_shape()\n",
        "        if not layer.output_shape:\n",
        "            layer.output_shape = layer.input_shape\n",
        "\n",
        "    \n",
        "    for i, layer in enumerate(network):\n",
        "        print(i,layer.input_shape,layer.output_shape)\n",
        "    \n",
        "    \n",
        "    # initialize layers & create one optimizer per layer\n",
        "    layer_shapes = [(layer.input_shape, layer.output_shape) for layer in network]\n",
        "    initializer.set_layer_shapes(layer_shapes)\n",
        "    optimizers = []\n",
        "    weights    = []\n",
        "    for i, layer in enumerate(network):\n",
        "        initializer.set_layer_index(i)\n",
        "        param_shapes = layer.initialize(initializer)\n",
        "        optimizers.append(Optimizer(OptimizerBaseClass, optimizerArgs, param_shapes) if layer.trainable else None)\n",
        "        weights.append(layer.get_weights() if layer.trainable else None)\n",
        "\n",
        "    # return list of (layer, optimizer)\n",
        "    return list(zip(network, optimizers, weights))\n",
        "\n",
        "def summary(model):\n",
        "    for layer, _ in model:\n",
        "        print(layer.input_shape, '\\t', layer.output_shape)\n",
        "\n",
        "def forward(model, input):\n",
        "    output = input\n",
        "    for layer, optimizer, weight in model:\n",
        "        output = layer.forward(output)     \n",
        "    return output\n",
        "\n",
        "\n",
        "def forward_batch(model, input, batch_size=1):\n",
        "    output = input\n",
        "    for layer, optimizer, weight in model:\n",
        "        output = layer.forward_batch(output, batch_size)\n",
        "    return output\n",
        "\n",
        "def backward(model, output):\n",
        "    error = output\n",
        "    layer_count=1\n",
        "    #grad=None\n",
        "    \n",
        "    for layer, optimizer, weight in reversed(model):\n",
        "        if layer_count<=10:\n",
        "            error, gradients = layer.backward(error)\n",
        "            if layer.trainable:\n",
        "                #print(gradients[0].shape)\n",
        "                #print(np.sum(gradients[0]))\n",
        "                #print(gradients[1].shape)\n",
        "                #print(np.sum(gradients[1]))\n",
        "                optimizer.set_gradients(gradients)\n",
        "                #grad=gradients\n",
        "            #layer_count+=1\n",
        "    #return grad\n",
        "    return error\n",
        "\n",
        "def backward_batch(model, output, batch_size):\n",
        "    error = output\n",
        "    layer_count=1\n",
        "    #grad=None\n",
        "    \n",
        "    for layer, optimizer, weight in reversed(model):\n",
        "        if layer_count<=10:\n",
        "            error, gradients = layer.backward_batch(error, batch_size)\n",
        "            if layer.trainable:\n",
        "                #print(gradients[0][0].shape)\n",
        "                #print(np.sum(gradients[0][0]))\n",
        "                #print(gradients[0][1].shape)\n",
        "                #print(np.sum(gradients[0][1]))\n",
        "                optimizer.set_gradients_batch(gradients,batch_size)\n",
        "                #grad=gradients\n",
        "            #layer_count+=1\n",
        "    #return grad\n",
        "    return error\n",
        "\n",
        "def update(model, iteration):\n",
        "    check=True\n",
        "    for layer, optimizer, weight in model:\n",
        "        if layer.trainable:\n",
        "            check=layer.update(optimizer.get_gradients(iteration))\n",
        "            \n",
        "    return check\n",
        "\n",
        "#def get_weights(model):\n",
        "#    return model[:,2]\n",
        "#def set_weights(model, weights) : \n",
        "#    model[:,2]=weights\n",
        "\n",
        "def train_batch(model, loss, x_train, y_train, epochs, batch_size):\n",
        "    train_set_size = len(x_train)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        error = 0\n",
        "        for i in range(0, train_set_size, batch_size):\n",
        "            break_loop=False\n",
        "            print(f\"epoch: {epoch} batch:{i}\")\n",
        "            x=x_train[i:i+batch_size]\n",
        "            y=y_train[i:i+batch_size]          \n",
        "            output = forward_batch(model, x, batch_size)\n",
        "            tmp  =loss.call_batch(y, output, batch_size)\n",
        "            error+=tmp\n",
        "            #error += loss.call_batch(y, output, batch_size)\n",
        "            \n",
        "            if(np.isnan(np.sum(output))):\n",
        "                break_loop=True\n",
        "                print(\"output fail\")\n",
        "                #print(output)\n",
        "            else:    \n",
        "                print(\"output ok\")\n",
        "\n",
        "            check_backward=backward_batch(model, loss.prime_batch(y, output, batch_size), batch_size)\n",
        "\n",
        "            if(np.isnan(np.sum(check_backward))):\n",
        "                break_loop=True\n",
        "                print(\"backward fail\")\n",
        "                #print(check_backward)\n",
        "            else:    \n",
        "                print(\"backward ok\")\n",
        "             \n",
        "            check_update =update(model, epoch)\n",
        "            if(check_update==False):\n",
        "                print(\"update fail\")\n",
        "                break_loop=True\n",
        "            else:\n",
        "                print(\"update ok\")\n",
        "        \n",
        "            if(break_loop):\n",
        "                return\n",
        "\n",
        "\n",
        "            '''\n",
        "            if(np.isnan(tmp)):\n",
        "                print(epoch)\n",
        "                print('fuck')\n",
        "                print(y)\n",
        "                print(output)\n",
        "                break\n",
        "            '''\n",
        "            #print(\"error\",tmp)\n",
        "            \n",
        "            \n",
        "            #print(x.shape)\n",
        "            #print(y.shape)\n",
        "            #print(y)\n",
        "            #print(output.shape)\n",
        "            #print(output)\n",
        "            #print(loss.prime_batch(y, output,batch_size).shape)\n",
        "            #print(\"----\")\n",
        "            \n",
        "            #backward_batch(model, loss.prime_batch(y, output, batch_size), batch_size)\n",
        "            #print(\"back_pro\")\n",
        "            #update(model, epoch)\n",
        "            #print(\"update\")\n",
        "        #print(error)  \n",
        "        #print(epoch,\"-------\")     \n",
        "  \n",
        "        #error /= train_set_size\n",
        "        #print('%d/%d, error=%f' % (epoch, epochs, error))\n",
        "\n",
        "def train(model, loss, x_train, y_train, epochs, batch=1):\n",
        "    train_set_size = len(x_train)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        error = 0\n",
        "\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            #if epoch % batch == 0:\n",
        "            #  print(epoch,batch)\n",
        "            \n",
        "            output = forward(model, x)\n",
        "            error += loss.call(y, output)\n",
        "            \n",
        "            #print(y.shape)\n",
        "            #print(output.shape)\n",
        "            #print(loss.prime(y, output).shape)\n",
        "            #print(\"----\")\n",
        "            backward(model, loss.prime(y, output))\n",
        "            if epoch % batch == 0:\n",
        "                update(model, epoch)\n",
        "        #update(model, epoch)\n",
        "        error /= train_set_size\n",
        "        print('%d/%d, error=%f' % (epoch, epochs, error))\n",
        "\n",
        "def test(model, loss, x_test, y_test):\n",
        "    error = 0\n",
        "    for x, y in zip(x_test, y_test):\n",
        "        output = forward(model, x)\n",
        "        error += loss.call(y, output)\n",
        "    error /= len(x_test)\n",
        "    return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idVYH_kSJ6pY",
        "outputId": "cfd029b4-6a01-417f-be49-4dd781ecc63f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "0 (28, 28) (1, 784)\n",
            "1 None (1, 10)\n",
            "2 None None\n",
            "----\n",
            "0 (28, 28) (1, 784)\n",
            "1 (1, 784) (1, 10)\n",
            "2 (1, 10) (1, 10)\n"
          ]
        }
      ],
      "source": [
        "def load_data(n):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_train /= 255\n",
        "    y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_test /= 255\n",
        "    y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "    return x_train[:n], y_train[:n], x_test, y_test\n",
        "'''\n",
        "# load MNIST from server\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# training data : 60000 samples\n",
        "# reshape and normalize input data\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "# encode output which is a number in range [0,9] into a vector of size 10\n",
        "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "# same for test data : 10000 samples\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "'''\n",
        "\n",
        "model_architecture=[\n",
        "    Reshape((1, 784), input_shape=(28, 28)),\n",
        "    #Dense(50),\n",
        "    #Tanh(),\n",
        "    #Dense(20),\n",
        "    #Tanh(),\n",
        "    Dense(10),\n",
        "    Softmax()\n",
        "]\n",
        "\n",
        "\n",
        "model_single = create_model(model_architecture, Normal(), SGD, {'learning_rate': 0.5})\n",
        "model_batch=copy.deepcopy(model_single)\n",
        "mse = MSE()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_debug(model_single, model_batch, loss, x_train, y_train, epochs, batch_size=1):\n",
        "    train_set_size = len(x_train)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        error_single = 0\n",
        "        error_batch = 0\n",
        "\n",
        "        for x, y in zip(x_train, y_train):    \n",
        "            output = forward(model_single, x)\n",
        "            error_single += loss.call(y, output)\n",
        "\n",
        "            tmp=loss.prime(y, output)\n",
        "\n",
        "            er1=backward(model_single, loss.prime(y, output))\n",
        "            #print(len(er1))\n",
        "            #print(er1[0].shape)\n",
        "            #print(er1[0][0])\n",
        "            #print(er1[1].shape)\n",
        "            #print(er1[1])\n",
        "            #er1=np.array(er1)\n",
        "            #print(tmp.shape)\n",
        "            #print(np.sum(tmp))\n",
        "            #print(er1.shape)\n",
        "            #print(np.sum(er1))    \n",
        "            update(model_single, epoch)\n",
        "        #print('--------------------------')\n",
        "        for i in range(0, train_set_size, batch_size):\n",
        "            x_batch=x_train[i:i+batch_size]\n",
        "            y_batch=y_train[i:i+batch_size] \n",
        "            output_batch = forward_batch(model_batch, x_batch, batch_size)\n",
        "            error_batch +=loss.call_batch(y_batch, output_batch, batch_size)\n",
        "            \n",
        "            tmp=loss.prime_batch(y_batch, output_batch, batch_size)\n",
        "\n",
        "            er2=backward_batch(model_batch, loss.prime_batch(y_batch, output_batch, batch_size), batch_size)\n",
        "            update(model_batch, epoch)\n",
        "            #print(len(er2))\n",
        "            #print(er2[0][0])\n",
        "            #er2=np.array(er2)\n",
        "\n",
        "            #print(np.array(tmp).shape)\n",
        "            #print(np.sum(tmp))\n",
        "            \n",
        "            #print(er2.shape) \n",
        "            #print(np.sum(er2))  \n",
        "            '''\n",
        "            for x, y in zip(x_batch, y_batch):  \n",
        "                output = forward(model_batch, x)\n",
        "                error_batch += loss.call(y, output)\n",
        "                #backward(model_batch, loss.prime(y, output))    \n",
        "                #update(model_batch, epoch\n",
        "            '''\n",
        "        #er3=er1-er2\n",
        "        #print(np.sum(er3))\n",
        "        #update(model, epoch)\n",
        "        error_single /= train_set_size\n",
        "        error_batch /= train_set_size\n",
        "        #if error_single==error_batch:\n",
        "        print(f'{epoch}/{epochs}, error_single={error_single} , error_batch={error_batch}' )"
      ],
      "metadata": {
        "id": "kJNwP77v_JCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcQcpq-uPZY2",
        "outputId": "172d3db7-6200-4be9-a896-655d8132b173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1000, error_single=0.14995552824223526 , error_batch=0.01500196599676113\n",
            "2/1000, error_single=0.12762432405392327 , error_batch=0.013071456473037417\n",
            "3/1000, error_single=0.1086897044598518 , error_batch=0.012121126955214594\n",
            "4/1000, error_single=0.10096158152538838 , error_batch=0.011019596728542028\n",
            "5/1000, error_single=0.08788719953603838 , error_batch=0.009996118650742968\n",
            "6/1000, error_single=0.07941895378447128 , error_batch=0.008973885610363165\n",
            "7/1000, error_single=0.07389977675151062 , error_batch=0.007825519829844555\n",
            "8/1000, error_single=0.07031331233634991 , error_batch=0.007229291405009201\n",
            "9/1000, error_single=0.06835622167904433 , error_batch=0.006976808336242658\n",
            "10/1000, error_single=0.06563211055523475 , error_batch=0.00676195217227399\n",
            "11/1000, error_single=0.06381505968543139 , error_batch=0.006593093764013937\n",
            "12/1000, error_single=0.062083825302390906 , error_batch=0.006431619936216603\n",
            "13/1000, error_single=0.06048910602896773 , error_batch=0.006293279456195341\n",
            "14/1000, error_single=0.05961218883933195 , error_batch=0.006136803478803741\n",
            "15/1000, error_single=0.059107507297552736 , error_batch=0.006038258654827682\n",
            "16/1000, error_single=0.05813368686406423 , error_batch=0.005884006050382966\n",
            "17/1000, error_single=0.05718721764914067 , error_batch=0.005769611595248975\n",
            "18/1000, error_single=0.0563829471576771 , error_batch=0.005678715854952225\n",
            "19/1000, error_single=0.05591748924622049 , error_batch=0.005615468326627725\n",
            "20/1000, error_single=0.055406313394613806 , error_batch=0.005576129068204127\n",
            "21/1000, error_single=0.05485733893090193 , error_batch=0.005537802113256368\n",
            "22/1000, error_single=0.05414330095437607 , error_batch=0.005427567331258533\n",
            "23/1000, error_single=0.053645096103760455 , error_batch=0.005313929986794903\n",
            "24/1000, error_single=0.05315114259202531 , error_batch=0.005094759828930051\n",
            "25/1000, error_single=0.05278131980321317 , error_batch=0.004945265258224926\n",
            "26/1000, error_single=0.05245795005250359 , error_batch=0.004810560892747138\n",
            "27/1000, error_single=0.05208261781602322 , error_batch=0.004687401425236246\n",
            "28/1000, error_single=0.051832042251993796 , error_batch=0.004591972906804597\n",
            "29/1000, error_single=0.05147199673482233 , error_batch=0.004522713630993666\n",
            "30/1000, error_single=0.05058603606760969 , error_batch=0.004477223946121519\n",
            "31/1000, error_single=0.04960085417580026 , error_batch=0.00443720779693528\n",
            "32/1000, error_single=0.0473021486563233 , error_batch=0.004390183868351761\n",
            "33/1000, error_single=0.04608457620669938 , error_batch=0.004343707400418934\n",
            "34/1000, error_single=0.04477531986582223 , error_batch=0.004306651338697456\n",
            "35/1000, error_single=0.04399914319608099 , error_batch=0.004274821235915243\n",
            "36/1000, error_single=0.043382838690768 , error_batch=0.004243002473448341\n",
            "37/1000, error_single=0.04274807008027563 , error_batch=0.0042103018105612055\n",
            "38/1000, error_single=0.042135977130538564 , error_batch=0.004168920439253258\n",
            "39/1000, error_single=0.041599259668453736 , error_batch=0.004128251599149485\n",
            "40/1000, error_single=0.041122349776477524 , error_batch=0.004087163022069601\n",
            "41/1000, error_single=0.04066210304727045 , error_batch=0.004043953688275248\n",
            "42/1000, error_single=0.040326001003328504 , error_batch=0.004003341503535979\n",
            "43/1000, error_single=0.03999406479892195 , error_batch=0.003968332103847993\n",
            "44/1000, error_single=0.039753468731622825 , error_batch=0.003946046223091238\n",
            "45/1000, error_single=0.03948269846860225 , error_batch=0.003921419184101729\n",
            "46/1000, error_single=0.03926620233816295 , error_batch=0.003898502901594943\n",
            "47/1000, error_single=0.03911237058707377 , error_batch=0.0038707663267071543\n",
            "48/1000, error_single=0.03896687805561281 , error_batch=0.0038350229106054487\n",
            "49/1000, error_single=0.03884153561679062 , error_batch=0.00380574949335287\n",
            "50/1000, error_single=0.03871089395851534 , error_batch=0.0037800569023176585\n",
            "51/1000, error_single=0.038603361434504734 , error_batch=0.0037562029547993955\n",
            "52/1000, error_single=0.038503405595683764 , error_batch=0.003732864650149122\n",
            "53/1000, error_single=0.038406550732486146 , error_batch=0.0037231244779696217\n",
            "54/1000, error_single=0.03829052378337025 , error_batch=0.0037185397871766085\n",
            "55/1000, error_single=0.03814940571002951 , error_batch=0.003708243578440858\n",
            "56/1000, error_single=0.038031256340551 , error_batch=0.0036988953732580076\n",
            "57/1000, error_single=0.03793484159445597 , error_batch=0.0036917670636941098\n",
            "58/1000, error_single=0.03784776414057852 , error_batch=0.0036839450246442572\n",
            "59/1000, error_single=0.03767566626366831 , error_batch=0.003675267157312439\n",
            "60/1000, error_single=0.03764842488229153 , error_batch=0.0036678724172791873\n",
            "61/1000, error_single=0.03738709813216551 , error_batch=0.0036598270107426364\n",
            "62/1000, error_single=0.03723710498640969 , error_batch=0.0036525724905657735\n",
            "63/1000, error_single=0.03713063353522618 , error_batch=0.0036464389978638394\n",
            "64/1000, error_single=0.0369879282056338 , error_batch=0.0036408242064885706\n",
            "65/1000, error_single=0.03675564646299847 , error_batch=0.0036354746202289525\n",
            "66/1000, error_single=0.036695776937603286 , error_batch=0.0036279897893024804\n",
            "67/1000, error_single=0.03659915828694861 , error_batch=0.0036184831322454755\n",
            "68/1000, error_single=0.03654519657004203 , error_batch=0.00361260016149079\n",
            "69/1000, error_single=0.0364685313024673 , error_batch=0.0035989477554259513\n",
            "70/1000, error_single=0.0363879948718165 , error_batch=0.0035753456786086\n",
            "71/1000, error_single=0.03627366652556201 , error_batch=0.0035613769142172854\n",
            "72/1000, error_single=0.0362292142285402 , error_batch=0.003558586627460707\n",
            "73/1000, error_single=0.036157307661848735 , error_batch=0.003547225180668696\n",
            "74/1000, error_single=0.03611819720476115 , error_batch=0.003535935708969145\n",
            "75/1000, error_single=0.03606633888061525 , error_batch=0.003528049503023105\n",
            "76/1000, error_single=0.036024419155905145 , error_batch=0.0035208918010000327\n",
            "77/1000, error_single=0.03597330323066224 , error_batch=0.0035139075166786622\n",
            "78/1000, error_single=0.035895875698066744 , error_batch=0.003506144699648508\n",
            "79/1000, error_single=0.03566171809653765 , error_batch=0.003499180969302544\n",
            "80/1000, error_single=0.03541005037696838 , error_batch=0.0034883799694641125\n",
            "81/1000, error_single=0.035199391980577394 , error_batch=0.0034336073334574747\n",
            "82/1000, error_single=0.03502332991009255 , error_batch=0.0033732114627961812\n",
            "83/1000, error_single=0.034758564189820824 , error_batch=0.0032488232905557\n",
            "84/1000, error_single=0.03455736044661264 , error_batch=0.003177816751486239\n",
            "85/1000, error_single=0.034224859648565975 , error_batch=0.003117060928676518\n",
            "86/1000, error_single=0.03396045067191813 , error_batch=0.0030844412480629\n",
            "87/1000, error_single=0.03302336637952294 , error_batch=0.0030427492317525503\n",
            "88/1000, error_single=0.031960946574949634 , error_batch=0.002968269991379559\n",
            "89/1000, error_single=0.03125717192292729 , error_batch=0.0029154258961442583\n",
            "90/1000, error_single=0.03079119510227032 , error_batch=0.002856629549600817\n",
            "91/1000, error_single=0.030360443782624078 , error_batch=0.0028352409057940445\n",
            "92/1000, error_single=0.029918400265549566 , error_batch=0.002819242887466162\n",
            "93/1000, error_single=0.0292596219577332 , error_batch=0.0028062709064226887\n",
            "94/1000, error_single=0.02894925908159329 , error_batch=0.0027854320763284132\n",
            "95/1000, error_single=0.02881183349455923 , error_batch=0.002743861008735449\n",
            "96/1000, error_single=0.028640091741300718 , error_batch=0.002704338874016715\n",
            "97/1000, error_single=0.028386274893518724 , error_batch=0.002679968165718494\n",
            "98/1000, error_single=0.027754981614233853 , error_batch=0.0026530500085190133\n",
            "99/1000, error_single=0.026472714332507252 , error_batch=0.0026141792521556574\n",
            "100/1000, error_single=0.022685355559411396 , error_batch=0.0025935012519094375\n",
            "101/1000, error_single=0.019586983929319304 , error_batch=0.0025758841400452133\n",
            "102/1000, error_single=0.017762482668341052 , error_batch=0.002556978400458828\n",
            "103/1000, error_single=0.016740932630830225 , error_batch=0.0025265988767294435\n",
            "104/1000, error_single=0.015991592604744333 , error_batch=0.0024941149149284286\n",
            "105/1000, error_single=0.016022541850381895 , error_batch=0.0024779132981389467\n",
            "106/1000, error_single=0.01497074593626253 , error_batch=0.0024650854307472873\n",
            "107/1000, error_single=0.014249323415357186 , error_batch=0.0024533742465172688\n",
            "108/1000, error_single=0.013890836110939133 , error_batch=0.0024414032800796955\n",
            "109/1000, error_single=0.0135326843569574 , error_batch=0.002430681017963391\n",
            "110/1000, error_single=0.013179290054669618 , error_batch=0.002412540884039284\n",
            "111/1000, error_single=0.012726377863333515 , error_batch=0.002393106638943585\n",
            "112/1000, error_single=0.012363957442641245 , error_batch=0.0023811471791889663\n",
            "113/1000, error_single=0.012101513109433224 , error_batch=0.0023674054982107257\n",
            "114/1000, error_single=0.011875804991740482 , error_batch=0.00235394088368658\n",
            "115/1000, error_single=0.011553706989933474 , error_batch=0.002343493574319548\n",
            "116/1000, error_single=0.011277306304577078 , error_batch=0.0023296347191738755\n",
            "117/1000, error_single=0.011071963224685207 , error_batch=0.0023072682944170805\n",
            "118/1000, error_single=0.010834022155428561 , error_batch=0.0022833835262752815\n",
            "119/1000, error_single=0.01063410275638924 , error_batch=0.002256884572957521\n",
            "120/1000, error_single=0.010512083722583115 , error_batch=0.0022422898475469443\n",
            "121/1000, error_single=0.010425625569280757 , error_batch=0.002231599682522725\n",
            "122/1000, error_single=0.010329754318606794 , error_batch=0.0022222043908367564\n",
            "123/1000, error_single=0.01011791751548532 , error_batch=0.0022148797756290253\n",
            "124/1000, error_single=0.00982457032454091 , error_batch=0.0022093587513717355\n",
            "125/1000, error_single=0.009605739275266688 , error_batch=0.00220470103396658\n",
            "126/1000, error_single=0.009451531002357781 , error_batch=0.0021997626364849508\n",
            "127/1000, error_single=0.009361854177377858 , error_batch=0.002193852777090104\n",
            "128/1000, error_single=0.00928637382745615 , error_batch=0.0021878288973895617\n",
            "129/1000, error_single=0.009137639383056121 , error_batch=0.0021831677565194297\n",
            "130/1000, error_single=0.008987427537144559 , error_batch=0.002179345645754345\n",
            "131/1000, error_single=0.008835606689206328 , error_batch=0.002175759428657298\n",
            "132/1000, error_single=0.008704293281139745 , error_batch=0.0021716971042799495\n",
            "133/1000, error_single=0.008589570231836043 , error_batch=0.002165893356516209\n",
            "134/1000, error_single=0.008467539883731121 , error_batch=0.002158784665933785\n",
            "135/1000, error_single=0.008314712720936358 , error_batch=0.002153196207502006\n",
            "136/1000, error_single=0.00821311254452474 , error_batch=0.002149575854105682\n",
            "137/1000, error_single=0.007957579415937515 , error_batch=0.0021468641496086086\n",
            "138/1000, error_single=0.00784127965121482 , error_batch=0.002144183274794846\n",
            "139/1000, error_single=0.007773278980108232 , error_batch=0.002141657389768948\n",
            "140/1000, error_single=0.007706021032318324 , error_batch=0.0021390603383528934\n",
            "141/1000, error_single=0.0076313203638840735 , error_batch=0.0021360573552817986\n",
            "142/1000, error_single=0.007530365512180875 , error_batch=0.002131843550534819\n",
            "143/1000, error_single=0.0074205997217558235 , error_batch=0.002123994388106123\n",
            "144/1000, error_single=0.007240695981374281 , error_batch=0.0021197526662313166\n",
            "145/1000, error_single=0.007132970799294589 , error_batch=0.0021168807787615017\n",
            "146/1000, error_single=0.007058612430707645 , error_batch=0.002114188947493941\n",
            "147/1000, error_single=0.0069950462973697326 , error_batch=0.002111504342536748\n",
            "148/1000, error_single=0.006955149371124761 , error_batch=0.002108983731604766\n",
            "149/1000, error_single=0.006924517846989119 , error_batch=0.00210664654035956\n",
            "150/1000, error_single=0.0068794167341514195 , error_batch=0.0021045074773255045\n",
            "151/1000, error_single=0.006808455398819807 , error_batch=0.002102536819997671\n",
            "152/1000, error_single=0.006779777694382293 , error_batch=0.0021006181026801147\n",
            "153/1000, error_single=0.0067458233621705485 , error_batch=0.0020985701684311984\n",
            "154/1000, error_single=0.006725575236038651 , error_batch=0.002096094456585507\n",
            "155/1000, error_single=0.006687901553537533 , error_batch=0.002092677672807307\n",
            "156/1000, error_single=0.006661497355715893 , error_batch=0.00208831282779715\n",
            "157/1000, error_single=0.006619179347743066 , error_batch=0.0020851804576778607\n",
            "158/1000, error_single=0.006595996493758095 , error_batch=0.0020831947045871686\n",
            "159/1000, error_single=0.006565280043949626 , error_batch=0.002081578769201279\n",
            "160/1000, error_single=0.00655302043623066 , error_batch=0.002080180537385795\n",
            "161/1000, error_single=0.00653206324731316 , error_batch=0.0020789434471845053\n",
            "162/1000, error_single=0.0065234860862782 , error_batch=0.0020778168140188707\n",
            "163/1000, error_single=0.00650602597628358 , error_batch=0.0020767680477286007\n",
            "164/1000, error_single=0.0064953754318519364 , error_batch=0.002075777061946128\n",
            "165/1000, error_single=0.006474512032975368 , error_batch=0.0020748286398532606\n",
            "166/1000, error_single=0.006447300121673415 , error_batch=0.0020739097646955804\n",
            "167/1000, error_single=0.0063795549918810104 , error_batch=0.0020730081470667606\n",
            "168/1000, error_single=0.006251093664383017 , error_batch=0.0020721104132022574\n",
            "169/1000, error_single=0.0062089951111052215 , error_batch=0.002071200434018153\n",
            "170/1000, error_single=0.006181107827313363 , error_batch=0.0020702571229392884\n",
            "171/1000, error_single=0.006156165571432369 , error_batch=0.002069251774984658\n",
            "172/1000, error_single=0.006123338500533991 , error_batch=0.002068144532993232\n",
            "173/1000, error_single=0.0060905446573845225 , error_batch=0.002066879650778324\n",
            "174/1000, error_single=0.0060766121085946275 , error_batch=0.002065382207894974\n",
            "175/1000, error_single=0.0060649088252647245 , error_batch=0.00206359121981726\n",
            "176/1000, error_single=0.006058533475969922 , error_batch=0.0020616045223379367\n",
            "177/1000, error_single=0.0060499075309934135 , error_batch=0.002059730929661604\n",
            "178/1000, error_single=0.00604657834491676 , error_batch=0.0020581734736270832\n",
            "179/1000, error_single=0.006039377738028139 , error_batch=0.0020568963250423853\n",
            "180/1000, error_single=0.006037661736533492 , error_batch=0.0020557839291034828\n",
            "181/1000, error_single=0.006031197459240788 , error_batch=0.0020546369028138244\n",
            "182/1000, error_single=0.006030399257131049 , error_batch=0.0020526998897861344\n",
            "183/1000, error_single=0.006024398416655091 , error_batch=0.002049315707218499\n",
            "184/1000, error_single=0.006024126325525259 , error_batch=0.0020464482606057663\n",
            "185/1000, error_single=0.006018449270147128 , error_batch=0.0020444839118714123\n",
            "186/1000, error_single=0.0060184597271444335 , error_batch=0.0020430418173386124\n",
            "187/1000, error_single=0.006013008843210757 , error_batch=0.0020418800816072017\n",
            "188/1000, error_single=0.006013138528434945 , error_batch=0.002040900042592676\n",
            "189/1000, error_single=0.006007832462392154 , error_batch=0.0020400444809648456\n",
            "190/1000, error_single=0.006007962273610897 , error_batch=0.0020392762540304356\n",
            "191/1000, error_single=0.006002722439596882 , error_batch=0.0020385724481168928\n",
            "192/1000, error_single=0.006002747853771014 , error_batch=0.002037918073449914\n",
            "193/1000, error_single=0.005997472641345415 , error_batch=0.0020373032072132846\n",
            "194/1000, error_single=0.005997250771599022 , error_batch=0.0020367210585054353\n",
            "195/1000, error_single=0.00599172599041032 , error_batch=0.0020361667270681425\n",
            "196/1000, error_single=0.005990894416361455 , error_batch=0.002035636502408316\n",
            "197/1000, error_single=0.005984401234406889 , error_batch=0.0020351274737902604\n",
            "198/1000, error_single=0.005981464592376331 , error_batch=0.0020346372842366908\n",
            "199/1000, error_single=0.005970262287357334 , error_batch=0.0020341639713557127\n",
            "200/1000, error_single=0.005954829961160839 , error_batch=0.0020337058515974386\n",
            "201/1000, error_single=0.005907750369134114 , error_batch=0.0020332614311872636\n",
            "202/1000, error_single=0.005875129434467343 , error_batch=0.0020328293342366855\n",
            "203/1000, error_single=0.005863900598764792 , error_batch=0.0020324082446750214\n",
            "204/1000, error_single=0.00586214153744025 , error_batch=0.002031996860644872\n",
            "205/1000, error_single=0.005855777635052859 , error_batch=0.0020315938600398327\n",
            "206/1000, error_single=0.005856213130150531 , error_batch=0.0020311978747076923\n",
            "207/1000, error_single=0.005850742271185833 , error_batch=0.002030807469226867\n",
            "208/1000, error_single=0.005851673918709456 , error_batch=0.0020304211186721673\n",
            "209/1000, error_single=0.005846624116367108 , error_batch=0.0020300371786038333\n",
            "210/1000, error_single=0.005847622974370653 , error_batch=0.0020296538391958332\n",
            "211/1000, error_single=0.0058427880165806845 , error_batch=0.002029269053070566\n",
            "212/1000, error_single=0.005843702278895291 , error_batch=0.0020288804215200284\n",
            "213/1000, error_single=0.005838923908451253 , error_batch=0.0020284850138235677\n",
            "214/1000, error_single=0.005839611618926971 , error_batch=0.0020280790744107904\n",
            "215/1000, error_single=0.005834685809195223 , error_batch=0.002027657532151204\n",
            "216/1000, error_single=0.005834862933121616 , error_batch=0.0020272131409823585\n",
            "217/1000, error_single=0.0058294360308271155 , error_batch=0.0020267348932315144\n",
            "218/1000, error_single=0.00582842312397637 , error_batch=0.0020262049088394154\n",
            "219/1000, error_single=0.005821635756938355 , error_batch=0.0020255919203668814\n",
            "220/1000, error_single=0.005817603509798524 , error_batch=0.002024836538208568\n",
            "221/1000, error_single=0.0058067362693772235 , error_batch=0.002023812427682249\n",
            "222/1000, error_single=0.00579413220467058 , error_batch=0.0020221607312064225\n",
            "223/1000, error_single=0.005769134631117392 , error_batch=0.0020186611998248114\n",
            "224/1000, error_single=0.00574039034908734 , error_batch=0.002014876234452688\n",
            "225/1000, error_single=0.005715044672289666 , error_batch=0.002012939623695551\n",
            "226/1000, error_single=0.00570151480483169 , error_batch=0.002011247314863813\n",
            "227/1000, error_single=0.005684390170260739 , error_batch=0.002009090972234932\n",
            "228/1000, error_single=0.005672343601208611 , error_batch=0.002005033462874156\n",
            "229/1000, error_single=0.005653081563352762 , error_batch=0.002001403892268096\n",
            "230/1000, error_single=0.005639135886508674 , error_batch=0.001999271353916189\n",
            "231/1000, error_single=0.005620358932558412 , error_batch=0.0019978249820395404\n",
            "232/1000, error_single=0.005610928514552987 , error_batch=0.0019965606388658887\n",
            "233/1000, error_single=0.0055986938771586305 , error_batch=0.0019951475623176946\n",
            "234/1000, error_single=0.005593732281177367 , error_batch=0.0019932278781837477\n",
            "235/1000, error_single=0.005586491748907727 , error_batch=0.001990364130444685\n",
            "236/1000, error_single=0.005583664820688464 , error_batch=0.0019874375122701598\n",
            "237/1000, error_single=0.005578562585986942 , error_batch=0.0019855302751592805\n",
            "238/1000, error_single=0.005576709587024848 , error_batch=0.001984074557852809\n",
            "239/1000, error_single=0.0055727478365149566 , error_batch=0.00198270020065517\n",
            "240/1000, error_single=0.00557133566814055 , error_batch=0.0019815138729414694\n",
            "241/1000, error_single=0.005568079812746974 , error_batch=0.001979564954138384\n",
            "242/1000, error_single=0.005566831487347526 , error_batch=0.0019651477974793686\n",
            "243/1000, error_single=0.005564041448973857 , error_batch=0.001962572336744315\n",
            "244/1000, error_single=0.005562781609114851 , error_batch=0.0019610665479897036\n",
            "245/1000, error_single=0.005560289407362682 , error_batch=0.0019601336463185995\n",
            "246/1000, error_single=0.005558865078936915 , error_batch=0.001959266345285251\n",
            "247/1000, error_single=0.005556513170337556 , error_batch=0.001958449220244634\n",
            "248/1000, error_single=0.0055547255386910206 , error_batch=0.0019576348836794996\n",
            "249/1000, error_single=0.0055522960136010985 , error_batch=0.0019568151190239983\n",
            "250/1000, error_single=0.005549768316009766 , error_batch=0.0019559793704042668\n",
            "251/1000, error_single=0.005546798748928125 , error_batch=0.0019551198786160015\n",
            "252/1000, error_single=0.005542543547738705 , error_batch=0.0019542176876069916\n",
            "253/1000, error_single=0.0055375416940039715 , error_batch=0.0019532152846143853\n",
            "254/1000, error_single=0.005527892614183229 , error_batch=0.0019519671005916602\n",
            "255/1000, error_single=0.005512966685445843 , error_batch=0.0019503423063349878\n",
            "256/1000, error_single=0.0054767197603469535 , error_batch=0.0019486484155688726\n",
            "257/1000, error_single=0.005431211330812708 , error_batch=0.0019473627423765335\n",
            "258/1000, error_single=0.005403465376432757 , error_batch=0.0019464619929343745\n",
            "259/1000, error_single=0.005371747023685034 , error_batch=0.0019457656774233662\n",
            "260/1000, error_single=0.005345494202796467 , error_batch=0.0019451738587464174\n",
            "261/1000, error_single=0.00533665433696692 , error_batch=0.0019446409296877253\n",
            "262/1000, error_single=0.005330030581664955 , error_batch=0.0019441450952767554\n",
            "263/1000, error_single=0.005327584644105331 , error_batch=0.001943675048631515\n",
            "264/1000, error_single=0.005323539749628725 , error_batch=0.0019432244879494943\n",
            "265/1000, error_single=0.005321922307653539 , error_batch=0.0019427896523834705\n",
            "266/1000, error_single=0.005319031514352444 , error_batch=0.0019423681115880059\n",
            "267/1000, error_single=0.005317805540777358 , error_batch=0.0019419581266924158\n",
            "268/1000, error_single=0.00531564963481453 , error_batch=0.0019415583133203618\n",
            "269/1000, error_single=0.005314611725133101 , error_batch=0.0019411674591091866\n",
            "270/1000, error_single=0.005312858577342209 , error_batch=0.0019407844251141482\n",
            "271/1000, error_single=0.005311829247808358 , error_batch=0.0019404080907821745\n",
            "272/1000, error_single=0.005310237565240531 , error_batch=0.001940037320707912\n",
            "273/1000, error_single=0.005309084470260069 , error_batch=0.001939670940163987\n",
            "274/1000, error_single=0.005307459626493466 , error_batch=0.0019393077112049857\n",
            "275/1000, error_single=0.0053060438900765705 , error_batch=0.0019389463029234962\n",
            "276/1000, error_single=0.005304144209327767 , error_batch=0.0019385852496179455\n",
            "277/1000, error_single=0.0053021994085531805 , error_batch=0.0019382228892336818\n",
            "278/1000, error_single=0.005299531520064596 , error_batch=0.0019378572711660543\n",
            "279/1000, error_single=0.005296310494244704 , error_batch=0.0019374860163778778\n",
            "280/1000, error_single=0.005291445540530911 , error_batch=0.0019371061016852115\n",
            "281/1000, error_single=0.005284242473356211 , error_batch=0.0019367135198535862\n",
            "282/1000, error_single=0.005271946711496846 , error_batch=0.0019363027295972684\n",
            "283/1000, error_single=0.005250700098290711 , error_batch=0.0019358657382508384\n",
            "284/1000, error_single=0.005227715843600165 , error_batch=0.0019353905218660232\n",
            "285/1000, error_single=0.005212516139493752 , error_batch=0.0019348582188092745\n",
            "286/1000, error_single=0.005204773979720461 , error_batch=0.0019342380226912961\n",
            "287/1000, error_single=0.00519707924913937 , error_batch=0.001933477822201312\n",
            "288/1000, error_single=0.005189213797590265 , error_batch=0.0019324875462519494\n",
            "289/1000, error_single=0.00517760823701236 , error_batch=0.0019311135767998593\n",
            "290/1000, error_single=0.0051673240953044 , error_batch=0.0019291470983527498\n",
            "291/1000, error_single=0.005155654573402966 , error_batch=0.0019267100565754636\n",
            "292/1000, error_single=0.0051519789609036845 , error_batch=0.0019246800122014829\n",
            "293/1000, error_single=0.005148425486399569 , error_batch=0.001923210306345334\n",
            "294/1000, error_single=0.005144966802831585 , error_batch=0.0019218627944590687\n",
            "295/1000, error_single=0.005142501993163034 , error_batch=0.001920539281566181\n",
            "296/1000, error_single=0.005139937107139421 , error_batch=0.0019194511737566273\n",
            "297/1000, error_single=0.005138318727985756 , error_batch=0.001918638900620068\n",
            "298/1000, error_single=0.005136352529192269 , error_batch=0.001917972703562507\n",
            "299/1000, error_single=0.0051351336770844355 , error_batch=0.0019173821660150485\n",
            "300/1000, error_single=0.005133536869587551 , error_batch=0.0019168418458903283\n",
            "301/1000, error_single=0.00513237766136436 , error_batch=0.0019163362804784274\n",
            "302/1000, error_single=0.005131010337994222 , error_batch=0.0019158551783407386\n",
            "303/1000, error_single=0.005129769004125843 , error_batch=0.0019153919571276083\n",
            "304/1000, error_single=0.005128576572977424 , error_batch=0.0019149421561798791\n",
            "305/1000, error_single=0.00512721645790662 , error_batch=0.001914502700673898\n",
            "306/1000, error_single=0.0051261590045897495 , error_batch=0.0019140712747827409\n",
            "307/1000, error_single=0.005124675865496297 , error_batch=0.0019136457628822219\n",
            "308/1000, error_single=0.0051237010332299575 , error_batch=0.0019132237087032854\n",
            "309/1000, error_single=0.005122095091046919 , error_batch=0.0019128017468977513\n",
            "310/1000, error_single=0.005121139003986795 , error_batch=0.0019123749266585141\n",
            "311/1000, error_single=0.005119399850183313 , error_batch=0.001911935805622987\n",
            "312/1000, error_single=0.005118394682656322 , error_batch=0.0019114730377359944\n",
            "313/1000, error_single=0.005116492939461603 , error_batch=0.001910968896637929\n",
            "314/1000, error_single=0.005115383817905515 , error_batch=0.0019103946566827216\n",
            "315/1000, error_single=0.00511328047398649 , error_batch=0.001909701849252253\n",
            "316/1000, error_single=0.005112071532220255 , error_batch=0.0019088063389518222\n",
            "317/1000, error_single=0.005109771598738725 , error_batch=0.001907564483599914\n",
            "318/1000, error_single=0.005108611005825788 , error_batch=0.001905775288301931\n",
            "319/1000, error_single=0.005106265409955227 , error_batch=0.0019034450780278898\n",
            "320/1000, error_single=0.005105436932894918 , error_batch=0.001901352969326239\n",
            "321/1000, error_single=0.0051033000990586466 , error_batch=0.0019001370933609274\n",
            "322/1000, error_single=0.0051029095939846576 , error_batch=0.0018931271058775765\n",
            "323/1000, error_single=0.00510103302212094 , error_batch=0.0018833894677059877\n",
            "324/1000, error_single=0.005100878910117828 , error_batch=0.0018811842688940096\n",
            "325/1000, error_single=0.005099112140516345 , error_batch=0.0018797057525066353\n",
            "326/1000, error_single=0.005099001191340841 , error_batch=0.0018777405060226965\n",
            "327/1000, error_single=0.005097209532209901 , error_batch=0.001874339667664472\n",
            "328/1000, error_single=0.0050970422428956415 , error_batch=0.0018696448587032987\n",
            "329/1000, error_single=0.005095118148931286 , error_batch=0.0018676039140997688\n",
            "330/1000, error_single=0.005094808067115151 , error_batch=0.0018665330107024867\n",
            "331/1000, error_single=0.00509262546570495 , error_batch=0.0018657037986444642\n",
            "332/1000, error_single=0.005092047338013596 , error_batch=0.0018650364051859517\n",
            "333/1000, error_single=0.005089405871055537 , error_batch=0.0018643419283656114\n",
            "334/1000, error_single=0.00508833784440482 , error_batch=0.0018637278730663067\n",
            "335/1000, error_single=0.005084827641406431 , error_batch=0.0018630480191592293\n",
            "336/1000, error_single=0.005082854426978221 , error_batch=0.0018624305848841175\n",
            "337/1000, error_single=0.005077487408846919 , error_batch=0.0018617255507870248\n",
            "338/1000, error_single=0.005074179183565264 , error_batch=0.0018610701444168789\n",
            "339/1000, error_single=0.005065291338470385 , error_batch=0.001860335209719285\n",
            "340/1000, error_single=0.005061841709378508 , error_batch=0.0018596697488375742\n",
            "341/1000, error_single=0.005053005553622909 , error_batch=0.0018589964465119799\n",
            "342/1000, error_single=0.005044513105552198 , error_batch=0.0018584238772908137\n",
            "343/1000, error_single=0.005036674844831386 , error_batch=0.0018578899217383614\n",
            "344/1000, error_single=0.005014483000083923 , error_batch=0.001857422935194813\n",
            "345/1000, error_single=0.005000890057750289 , error_batch=0.00185698823721931\n",
            "346/1000, error_single=0.004974353783051567 , error_batch=0.0018565752278242769\n",
            "347/1000, error_single=0.004966895748434945 , error_batch=0.0018561872113713725\n",
            "348/1000, error_single=0.0049559272762915345 , error_batch=0.0018557917325770657\n",
            "349/1000, error_single=0.004953685496331243 , error_batch=0.0018554193858486205\n",
            "350/1000, error_single=0.00494958586379069 , error_batch=0.0018550224720518531\n",
            "351/1000, error_single=0.0049483547815077555 , error_batch=0.0018546508486151653\n",
            "352/1000, error_single=0.004946189199454975 , error_batch=0.0018542473760894533\n",
            "353/1000, error_single=0.004945298307427692 , error_batch=0.0018538753508947267\n",
            "354/1000, error_single=0.004943828522407674 , error_batch=0.0018534690098262398\n",
            "355/1000, error_single=0.004943101077200063 , error_batch=0.0018530956055975547\n",
            "356/1000, error_single=0.004941884329039941 , error_batch=0.001852673389594539\n",
            "357/1000, error_single=0.004941214624346524 , error_batch=0.0018522649402657589\n",
            "358/1000, error_single=0.004940085877422347 , error_batch=0.0018517631898284544\n",
            "359/1000, error_single=0.004939357381099557 , error_batch=0.0018512251297268416\n",
            "360/1000, error_single=0.0049382100750968 , error_batch=0.001850514620427134\n",
            "361/1000, error_single=0.0049372398174571865 , error_batch=0.0018497581853590289\n",
            "362/1000, error_single=0.004935805455009786 , error_batch=0.0018489796148118335\n",
            "363/1000, error_single=0.004934119326888595 , error_batch=0.0018484379669912042\n",
            "364/1000, error_single=0.004931393216799372 , error_batch=0.0018479507085796527\n",
            "365/1000, error_single=0.004926796224269863 , error_batch=0.0018476114726437745\n",
            "366/1000, error_single=0.004917025203720879 , error_batch=0.0018472597187720173\n",
            "367/1000, error_single=0.004898868839866074 , error_batch=0.001846990303550561\n",
            "368/1000, error_single=0.004892576885398482 , error_batch=0.0018466975031386096\n",
            "369/1000, error_single=0.004896716144829847 , error_batch=0.0018464562283327024\n",
            "370/1000, error_single=0.004889946918837717 , error_batch=0.0018461827564087343\n",
            "371/1000, error_single=0.004889469552964957 , error_batch=0.0018459413097521458\n",
            "372/1000, error_single=0.00489003777039452 , error_batch=0.001845657974245544\n",
            "373/1000, error_single=0.004894812042572584 , error_batch=0.0018453814098706022\n",
            "374/1000, error_single=0.004896908572235499 , error_batch=0.0018450548003803564\n",
            "375/1000, error_single=0.004901414876918421 , error_batch=0.0018446604980741149\n",
            "376/1000, error_single=0.0049024790074523325 , error_batch=0.0018444111807703527\n",
            "377/1000, error_single=0.0049038243595381425 , error_batch=0.001843134379563684\n",
            "378/1000, error_single=0.004903366754022748 , error_batch=0.0018333634472541577\n",
            "379/1000, error_single=0.004902460655568705 , error_batch=0.0018287526585288021\n",
            "380/1000, error_single=0.00490152040534824 , error_batch=0.0018278044077579673\n",
            "381/1000, error_single=0.004900017178703632 , error_batch=0.0018270765202386327\n",
            "382/1000, error_single=0.004899019907773274 , error_batch=0.0018265892606691698\n",
            "383/1000, error_single=0.004897510500855212 , error_batch=0.0018260968342255124\n",
            "384/1000, error_single=0.00489683903413587 , error_batch=0.00182572120857888\n",
            "385/1000, error_single=0.004895618723102323 , error_batch=0.001825311767473224\n",
            "386/1000, error_single=0.004895517507850186 , error_batch=0.0018249607874507056\n",
            "387/1000, error_single=0.004894374781875268 , error_batch=0.0018245651998880694\n",
            "388/1000, error_single=0.004894999541395316 , error_batch=0.0018241919517698435\n",
            "389/1000, error_single=0.004892486942442796 , error_batch=0.001823753263435339\n",
            "390/1000, error_single=0.004894797867590669 , error_batch=0.0018232921150195432\n",
            "391/1000, error_single=0.004882673272711857 , error_batch=0.0018227103231132444\n",
            "392/1000, error_single=0.004884324119008984 , error_batch=0.0018220115451949635\n",
            "393/1000, error_single=0.004808031669254571 , error_batch=0.001821041791202078\n",
            "394/1000, error_single=0.00475699604025723 , error_batch=0.0018198777310895636\n",
            "395/1000, error_single=0.0047496769035803845 , error_batch=0.001818688525113786\n",
            "396/1000, error_single=0.00474283220508737 , error_batch=0.0018179441160329141\n",
            "397/1000, error_single=0.004739414801676335 , error_batch=0.001817420092817953\n",
            "398/1000, error_single=0.00473686681123578 , error_batch=0.0018169251720184547\n",
            "399/1000, error_single=0.004735536912418347 , error_batch=0.0018165170953013238\n",
            "400/1000, error_single=0.004735673137922606 , error_batch=0.0018160553542707783\n",
            "401/1000, error_single=0.004734680565423252 , error_batch=0.0018156700484808848\n",
            "402/1000, error_single=0.004735862663285113 , error_batch=0.0018152264540283903\n",
            "403/1000, error_single=0.00473591257641458 , error_batch=0.0018148417102695766\n",
            "404/1000, error_single=0.004737275400703454 , error_batch=0.001814397978542344\n",
            "405/1000, error_single=0.004736797930363453 , error_batch=0.001813991500265058\n",
            "406/1000, error_single=0.00473763039926275 , error_batch=0.0018135156761099095\n",
            "407/1000, error_single=0.004736752487701617 , error_batch=0.0018130442726056013\n",
            "408/1000, error_single=0.004737233559658746 , error_batch=0.0018124631905920526\n",
            "409/1000, error_single=0.004736363744078545 , error_batch=0.0018118168484911252\n",
            "410/1000, error_single=0.00473666046116755 , error_batch=0.0018109333778474567\n",
            "411/1000, error_single=0.004735916945460927 , error_batch=0.0018097621075890199\n",
            "412/1000, error_single=0.00473607999734782 , error_batch=0.001807946536300025\n",
            "413/1000, error_single=0.004735446439298007 , error_batch=0.0018056014673254047\n",
            "414/1000, error_single=0.004735519111835053 , error_batch=0.001803639447132809\n",
            "415/1000, error_single=0.004734975126867715 , error_batch=0.001802463759193639\n",
            "416/1000, error_single=0.0047349809649432795 , error_batch=0.0018016280179230532\n",
            "417/1000, error_single=0.004734514807244845 , error_batch=0.0018010655296063405\n",
            "418/1000, error_single=0.0047344672534141595 , error_batch=0.001800476297176032\n",
            "419/1000, error_single=0.004734065468941851 , error_batch=0.0018000462328677498\n",
            "420/1000, error_single=0.00473397456270347 , error_batch=0.0017995103473601223\n",
            "421/1000, error_single=0.004733625632642298 , error_batch=0.0017990760829017063\n",
            "422/1000, error_single=0.004733498770074963 , error_batch=0.00179850557699055\n",
            "423/1000, error_single=0.004733193739781892 , error_batch=0.0017979682407932127\n",
            "424/1000, error_single=0.004733036715814217 , error_batch=0.0017972463731340713\n",
            "425/1000, error_single=0.004732768133684761 , error_batch=0.0017964189319204424\n",
            "426/1000, error_single=0.004732585651545942 , error_batch=0.0017952299277267803\n",
            "427/1000, error_single=0.004732347285326305 , error_batch=0.001793444023305507\n",
            "428/1000, error_single=0.004732143217920307 , error_batch=0.001790194631094508\n",
            "429/1000, error_single=0.004731929802562763 , error_batch=0.0017827404144371748\n",
            "430/1000, error_single=0.004731707404853568 , error_batch=0.0017687765255016042\n",
            "431/1000, error_single=0.004731514399208372 , error_batch=0.001732918682302188\n",
            "432/1000, error_single=0.004731276443465805 , error_batch=0.0016444943891227878\n",
            "433/1000, error_single=0.004731099856768096 , error_batch=0.0014930701849820258\n",
            "434/1000, error_single=0.004730848723486646 , error_batch=0.0012997466500555385\n",
            "435/1000, error_single=0.004730684970311368 , error_batch=0.0011191998279208174\n",
            "436/1000, error_single=0.0047304227076022925 , error_batch=0.0010024022233566393\n",
            "437/1000, error_single=0.004730268481425781 , error_batch=0.0008891283450651914\n",
            "438/1000, error_single=0.004729996835689621 , error_batch=0.0007906972807458445\n",
            "439/1000, error_single=0.004729848993933166 , error_batch=0.0007312673640536336\n",
            "440/1000, error_single=0.0047295694158279574 , error_batch=0.0006961082062102778\n",
            "441/1000, error_single=0.004729424867675696 , error_batch=0.0006576085784826092\n",
            "442/1000, error_single=0.004729138494745572 , error_batch=0.0006277834337799231\n",
            "443/1000, error_single=0.0047289940846589875 , error_batch=0.0006028484662930208\n",
            "444/1000, error_single=0.004728701700127271 , error_batch=0.0005844553075073191\n",
            "445/1000, error_single=0.004728554078866484 , error_batch=0.00056846920618229\n",
            "446/1000, error_single=0.0047282560438213364 , error_batch=0.0005479646480780214\n",
            "447/1000, error_single=0.0047281015159102826 , error_batch=0.0005392230901051028\n",
            "448/1000, error_single=0.004727797667880161 , error_batch=0.0005330616067535363\n",
            "449/1000, error_single=0.004727631998856077 , error_batch=0.0005291667860729691\n",
            "450/1000, error_single=0.004727321502335839 , error_batch=0.0005252092516286892\n",
            "451/1000, error_single=0.00472713965876248 , error_batch=0.0005185077086555233\n",
            "452/1000, error_single=0.004726820780013238 , error_batch=0.0005056401668013898\n",
            "453/1000, error_single=0.004726616556687107 , error_batch=0.0005032725250943665\n",
            "454/1000, error_single=0.004726286311237896 , error_batch=0.0005010694844092802\n",
            "455/1000, error_single=0.004726051766058272 , error_batch=0.0004980140437570689\n",
            "456/1000, error_single=0.0047257053426941085 , error_batch=0.0004946363503789335\n",
            "457/1000, error_single=0.004725429894654778 , error_batch=0.0004933512432065196\n",
            "458/1000, error_single=0.004725059671699877 , error_batch=0.0004921464931231354\n",
            "459/1000, error_single=0.004724728585662593 , error_batch=0.0004910558845428946\n",
            "460/1000, error_single=0.004724322370587841 , error_batch=0.0004899686375932074\n",
            "461/1000, error_single=0.004723914067201088 , error_batch=0.0004887442029853184\n",
            "462/1000, error_single=0.004723451773917779 , error_batch=0.00048729621189497896\n",
            "463/1000, error_single=0.004722932737885959 , error_batch=0.0004855126191021742\n",
            "464/1000, error_single=0.004722379698505777 , error_batch=0.0004832422568860182\n",
            "465/1000, error_single=0.00472169406784538 , error_batch=0.0004803674565901267\n",
            "466/1000, error_single=0.004720986449318074 , error_batch=0.00047641866728791117\n",
            "467/1000, error_single=0.0047200326075073655 , error_batch=0.00047252933535324204\n",
            "468/1000, error_single=0.004719042249253575 , error_batch=0.00047029388998854157\n",
            "469/1000, error_single=0.0047176135879915225 , error_batch=0.0004690452984338467\n",
            "470/1000, error_single=0.004716051789849697 , error_batch=0.0004681275059678048\n",
            "471/1000, error_single=0.004713663144873308 , error_batch=0.000467447319945939\n",
            "472/1000, error_single=0.00471077318543123 , error_batch=0.00046680026632282086\n",
            "473/1000, error_single=0.004706056696132333 , error_batch=0.0004662214240083939\n",
            "474/1000, error_single=0.004699445345441555 , error_batch=0.00046553672131631143\n",
            "475/1000, error_single=0.004687721641040632 , error_batch=0.00046470869912896185\n",
            "476/1000, error_single=0.004669179368162848 , error_batch=0.00046340954421125193\n",
            "477/1000, error_single=0.00464345140632142 , error_batch=0.0004612405094782191\n",
            "478/1000, error_single=0.004624848010106288 , error_batch=0.00045806468215329484\n",
            "479/1000, error_single=0.0046148031404365936 , error_batch=0.0004560674704675309\n",
            "480/1000, error_single=0.00460995243716323 , error_batch=0.00045455756034974183\n",
            "481/1000, error_single=0.0046048495436863636 , error_batch=0.0004538256738230966\n",
            "482/1000, error_single=0.004602205543269903 , error_batch=0.00045324297508122493\n",
            "483/1000, error_single=0.004595467284302326 , error_batch=0.0004527827913236926\n",
            "484/1000, error_single=0.004591681715997332 , error_batch=0.00045234295206035357\n",
            "485/1000, error_single=0.004576581628779572 , error_batch=0.0004518858179606488\n",
            "486/1000, error_single=0.004568035180934638 , error_batch=0.00045140799268030663\n",
            "487/1000, error_single=0.0045584106761805574 , error_batch=0.00045077682632795746\n",
            "488/1000, error_single=0.00455841801033529 , error_batch=0.00045009476985245257\n",
            "489/1000, error_single=0.004558082769411245 , error_batch=0.00044905166010618115\n",
            "490/1000, error_single=0.00455732478369032 , error_batch=0.0004479673093706588\n",
            "491/1000, error_single=0.00455703096751466 , error_batch=0.0004464208644198911\n",
            "492/1000, error_single=0.004557031548821313 , error_batch=0.0004451946197528225\n",
            "493/1000, error_single=0.004555872114985939 , error_batch=0.0004438348038148911\n",
            "494/1000, error_single=0.004555475114903439 , error_batch=0.00044289797875799553\n",
            "495/1000, error_single=0.004554616712811311 , error_batch=0.000441674075551255\n",
            "496/1000, error_single=0.004554437429429211 , error_batch=0.00044008312155624827\n",
            "497/1000, error_single=0.004553801509004364 , error_batch=0.0004367263498658003\n",
            "498/1000, error_single=0.004553607393555435 , error_batch=0.0004329737936334417\n",
            "499/1000, error_single=0.004552964219059234 , error_batch=0.0004306611265415277\n",
            "500/1000, error_single=0.004552730560494501 , error_batch=0.0004305276295810513\n",
            "501/1000, error_single=0.004552048448001594 , error_batch=0.0004301258205495435\n",
            "502/1000, error_single=0.004551763160164716 , error_batch=0.0004300441381660899\n",
            "503/1000, error_single=0.004551009194145744 , error_batch=0.0004298220407353159\n",
            "504/1000, error_single=0.004550608166616701 , error_batch=0.00042976337536698744\n",
            "505/1000, error_single=0.004549684965726128 , error_batch=0.00042961728161216195\n",
            "506/1000, error_single=0.004549038060156987 , error_batch=0.00042955878560362585\n",
            "507/1000, error_single=0.004547697550092491 , error_batch=0.000429446625113078\n",
            "508/1000, error_single=0.004546410452987754 , error_batch=0.0004293853358494129\n",
            "509/1000, error_single=0.004543782666900953 , error_batch=0.0004292941020361964\n",
            "510/1000, error_single=0.004540273094235849 , error_batch=0.0004292300544597023\n",
            "511/1000, error_single=0.004531373120059434 , error_batch=0.00042915403879604375\n",
            "512/1000, error_single=0.004512676281882959 , error_batch=0.00042908885275257254\n",
            "513/1000, error_single=0.004451495770695472 , error_batch=0.00042902490927670896\n",
            "514/1000, error_single=0.004434093554210634 , error_batch=0.0004289599117831046\n",
            "515/1000, error_single=0.004424391128510798 , error_batch=0.00042890575064343943\n",
            "516/1000, error_single=0.0044259194367916406 , error_batch=0.0004288418128998305\n",
            "517/1000, error_single=0.004421911560779616 , error_batch=0.00042879561255217374\n",
            "518/1000, error_single=0.004421989605905628 , error_batch=0.00042873322753716727\n",
            "519/1000, error_single=0.004420267020710492 , error_batch=0.0004286935300981371\n",
            "520/1000, error_single=0.00442131464814323 , error_batch=0.0004286329472029562\n",
            "521/1000, error_single=0.0044193850625818655 , error_batch=0.0004285986003484587\n",
            "522/1000, error_single=0.004419941392082485 , error_batch=0.00042853991853078173\n",
            "523/1000, error_single=0.004418074443928566 , error_batch=0.00042851001789683717\n",
            "524/1000, error_single=0.0044185572401104906 , error_batch=0.00042845324654393666\n",
            "525/1000, error_single=0.004416945012497579 , error_batch=0.0004284270818654446\n",
            "526/1000, error_single=0.004417377548594877 , error_batch=0.00042837217837410574\n",
            "527/1000, error_single=0.004415732706390478 , error_batch=0.00042834918799767\n",
            "528/1000, error_single=0.004416009728117629 , error_batch=0.00042829608112221636\n",
            "529/1000, error_single=0.004414277193443842 , error_batch=0.00042827581617558056\n",
            "530/1000, error_single=0.004414422680622129 , error_batch=0.0004282244204519707\n",
            "531/1000, error_single=0.004412495857159951 , error_batch=0.0004282065176810302\n",
            "532/1000, error_single=0.004412415768352142 , error_batch=0.00042815674226869016\n",
            "533/1000, error_single=0.0044100737729518185 , error_batch=0.00042814090382768953\n",
            "534/1000, error_single=0.004409575430878061 , error_batch=0.00042809265780376017\n",
            "535/1000, error_single=0.004406361253529817 , error_batch=0.00042807863631498055\n",
            "536/1000, error_single=0.00440491803082228 , error_batch=0.00042803183171396327\n",
            "537/1000, error_single=0.004399618296311366 , error_batch=0.0004280194192099644\n",
            "538/1000, error_single=0.004395532037978834 , error_batch=0.0004279739726381434\n",
            "539/1000, error_single=0.004384156469570016 , error_batch=0.0004279629923287777\n",
            "540/1000, error_single=0.0043711636608862224 , error_batch=0.00042791882569139287\n",
            "541/1000, error_single=0.004343077271891279 , error_batch=0.00042790912577861184\n",
            "542/1000, error_single=0.004321067414992961 , error_batch=0.00042786616646788716\n",
            "543/1000, error_single=0.004302459339203199 , error_batch=0.0004278576154478256\n",
            "544/1000, error_single=0.004297744118009194 , error_batch=0.0004278157962155636\n",
            "545/1000, error_single=0.004288423972416879 , error_batch=0.0004278082792665798\n",
            "546/1000, error_single=0.0042833836305805955 , error_batch=0.0004277675379231779\n",
            "547/1000, error_single=0.004269917404221952 , error_batch=0.00042776095409293114\n",
            "548/1000, error_single=0.00425427539514229 , error_batch=0.00042772123312112456\n",
            "549/1000, error_single=0.004201440417235435 , error_batch=0.0004277154931070742\n",
            "550/1000, error_single=0.00415328422759078 , error_batch=0.00042767673924389753\n",
            "551/1000, error_single=0.004133194594101393 , error_batch=0.00042767176361915924\n",
            "552/1000, error_single=0.004118489222587185 , error_batch=0.00042763392743726215\n",
            "553/1000, error_single=0.004094553183626382 , error_batch=0.0004276296452144237\n",
            "554/1000, error_single=0.004051031448972202 , error_batch=0.0004275926807196741\n",
            "555/1000, error_single=0.0039719763631214005 , error_batch=0.00042758902817401973\n",
            "556/1000, error_single=0.003934838879679517 , error_batch=0.00042755289242746693\n",
            "557/1000, error_single=0.003913587345190965 , error_batch=0.0004275498121215468\n",
            "558/1000, error_single=0.003905534079268226 , error_batch=0.0004275144648883708\n",
            "559/1000, error_single=0.0038997521759986655 , error_batch=0.0004275119048544925\n",
            "560/1000, error_single=0.0038977192727625374 , error_batch=0.00042747730827932053\n",
            "561/1000, error_single=0.0038937395093023635 , error_batch=0.0004274752213270339\n",
            "562/1000, error_single=0.003892581781038737 , error_batch=0.000427441339633088\n",
            "563/1000, error_single=0.003889859317974908 , error_batch=0.0004274396827563051\n",
            "564/1000, error_single=0.003889249858414024 , error_batch=0.00042740648196476033\n",
            "565/1000, error_single=0.003887103140609795 , error_batch=0.00042740521582860207\n",
            "566/1000, error_single=0.0038867960415834824 , error_batch=0.0004273726634938834\n",
            "567/1000, error_single=0.0038850177517027987 , error_batch=0.00042737175198525424\n",
            "568/1000, error_single=0.0038848748804263034 , error_batch=0.00042733981694159824\n",
            "569/1000, error_single=0.003883342631277895 , error_batch=0.00042733922677026744\n",
            "570/1000, error_single=0.003883303192326283 , error_batch=0.0004273078788844938\n",
            "571/1000, error_single=0.003881943463907506 , error_batch=0.0004273075792233221\n",
            "572/1000, error_single=0.0038819644976527557 , error_batch=0.00042727678914834805\n",
            "573/1000, error_single=0.003880737559182848 , error_batch=0.00042727675130243176\n",
            "574/1000, error_single=0.0038807911915534907 , error_batch=0.00042724649022546764\n",
            "575/1000, error_single=0.003879669960011939 , error_batch=0.0004272466873204325\n",
            "576/1000, error_single=0.0038797363521466685 , error_batch=0.00042721692669894486\n",
            "577/1000, error_single=0.0038787017422283183 , error_batch=0.00042721733337842185\n",
            "578/1000, error_single=0.003878765415481472 , error_batch=0.0004271880446557097\n",
            "579/1000, error_single=0.00387780275999825 , error_batch=0.0004271886367770557\n",
            "580/1000, error_single=0.003877850573070069 , error_batch=0.0004271597910675242\n",
            "581/1000, error_single=0.0038769473661647504 , error_batch=0.0004271605453829722\n",
            "582/1000, error_single=0.0038769666753129114 , error_batch=0.0004271321131146553\n",
            "583/1000, error_single=0.003876111051514171 , error_batch=0.0004271330069219546\n",
            "584/1000, error_single=0.0038760879365081274 , error_batch=0.00042710495742025363\n",
            "585/1000, error_single=0.003875267062857403 , error_batch=0.00042710596816196943\n",
            "586/1000, error_single=0.0038751839989717507 , error_batch=0.00042707826915343956\n",
            "587/1000, error_single=0.0038743818632051095 , error_batch=0.0004270793739366592\n",
            "588/1000, error_single=0.0038742139619652983 , error_batch=0.0004270519909442666\n",
            "589/1000, error_single=0.003873407485782834 , error_batch=0.00042705316594113864\n",
            "590/1000, error_single=0.003873115458396278 , error_batch=0.00042702606153160663\n",
            "591/1000, error_single=0.0038722665071054944 , error_batch=0.0004270272812038626\n",
            "592/1000, error_single=0.0038717817881755577 , error_batch=0.00042700041403168255\n",
            "593/1000, error_single=0.0038708185539464168 , error_batch=0.0004270016500955649\n",
            "594/1000, error_single=0.003870007804710123 , error_batch=0.00042697497366402164\n",
            "595/1000, error_single=0.0038687754035455248 , error_batch=0.0004269761936700642\n",
            "596/1000, error_single=0.003867343079819643 , error_batch=0.0004269496546922646\n",
            "597/1000, error_single=0.0038654507121764644 , error_batch=0.00042695082002716656\n",
            "598/1000, error_single=0.003862622905231023 , error_batch=0.0004269243562110312\n",
            "599/1000, error_single=0.0038588814655974805 , error_batch=0.00042692541921889705\n",
            "600/1000, error_single=0.0038522086684759623 , error_batch=0.0004268989562043184\n",
            "601/1000, error_single=0.0038424643674243764 , error_batch=0.00042689985594002996\n",
            "602/1000, error_single=0.00382487297604916 , error_batch=0.00042687330295635047\n",
            "603/1000, error_single=0.003804457312309168 , error_batch=0.0004268739587654146\n",
            "604/1000, error_single=0.0037875828799214346 , error_batch=0.000426847202300644\n",
            "605/1000, error_single=0.0037805387416059892 , error_batch=0.0004268475038524144\n",
            "606/1000, error_single=0.0037766367440152855 , error_batch=0.00042682039812861434\n",
            "607/1000, error_single=0.0037748368584238834 , error_batch=0.00042682018948109\n",
            "608/1000, error_single=0.003772978498735515 , error_batch=0.00042679254159814356\n",
            "609/1000, error_single=0.003771936212491309 , error_batch=0.0004267915948516692\n",
            "610/1000, error_single=0.003770599117120469 , error_batch=0.00042676314062407264\n",
            "611/1000, error_single=0.0037698857142083493 , error_batch=0.00042676111063425567\n",
            "612/1000, error_single=0.003768816416068138 , error_batch=0.00042673147330873066\n",
            "613/1000, error_single=0.0037682725599924483 , error_batch=0.00042672781618301414\n",
            "614/1000, error_single=0.003767403284620852 , error_batch=0.0004266964316556694\n",
            "615/1000, error_single=0.0037669584023132794 , error_batch=0.00042669024974859336\n",
            "616/1000, error_single=0.0037662276936442697 , error_batch=0.00042665622117245836\n",
            "617/1000, error_single=0.0037658549702431527 , error_batch=0.0004266459476873998\n",
            "618/1000, error_single=0.0037652284363125857 , error_batch=0.00042660773716318457\n",
            "619/1000, error_single=0.003764906547670122 , error_batch=0.00042659043779728315\n",
            "620/1000, error_single=0.003764360333848329 , error_batch=0.0004265451374553064\n",
            "621/1000, error_single=0.0037640783813751673 , error_batch=0.0004265147871987571\n",
            "622/1000, error_single=0.003763595136982892 , error_batch=0.00042645613765867664\n",
            "623/1000, error_single=0.0037633462676321993 , error_batch=0.0004263987171959198\n",
            "624/1000, error_single=0.0037629131125989502 , error_batch=0.00042631063544050317\n",
            "625/1000, error_single=0.0037626922929852825 , error_batch=0.0004261872380925876\n",
            "626/1000, error_single=0.003762299116106093 , error_batch=0.00042601690353485174\n",
            "627/1000, error_single=0.003762102542843865 , error_batch=0.0004256897791722128\n",
            "628/1000, error_single=0.0037617413994015902 , error_batch=0.0004252049147098292\n",
            "629/1000, error_single=0.003761566025769583 , error_batch=0.0004241307165001567\n",
            "630/1000, error_single=0.003761230658449854 , error_batch=0.00042290594423111447\n",
            "631/1000, error_single=0.003761074026808734 , error_batch=0.0004225287469874693\n",
            "632/1000, error_single=0.0037607594849390666 , error_batch=0.00042194501286020537\n",
            "633/1000, error_single=0.0037606196017248234 , error_batch=0.0004222413434670145\n",
            "634/1000, error_single=0.0037603219427381905 , error_batch=0.00042196316966212254\n",
            "635/1000, error_single=0.0037601971799040177 , error_batch=0.0004219978134614641\n",
            "636/1000, error_single=0.0037599132289601817 , error_batch=0.0004219085253119713\n",
            "637/1000, error_single=0.0037598022521332193 , error_batch=0.00042194248643932764\n",
            "638/1000, error_single=0.0037595294158238673 , error_batch=0.00042186317096317214\n",
            "639/1000, error_single=0.0037594311284445243 , error_batch=0.00042187421856704893\n",
            "640/1000, error_single=0.003759167251897383 , error_batch=0.000421825100758029\n",
            "641/1000, error_single=0.0037590807525336913 , error_batch=0.0004218274095786577\n",
            "642/1000, error_single=0.003758824009928773 , error_batch=0.00042179161876394804\n",
            "643/1000, error_single=0.0037587485598378763 , error_batch=0.0004217881842378322\n",
            "644/1000, error_single=0.0037584973701217973 , error_batch=0.0004217615779921322\n",
            "645/1000, error_single=0.0037584323686939386 , error_batch=0.00042175444937113225\n",
            "646/1000, error_single=0.003758185329739978 , error_batch=0.00042173404491413854\n",
            "647/1000, error_single=0.0037581302961395948 , error_batch=0.00042172429102664235\n",
            "648/1000, error_single=0.003757886132144975 , error_batch=0.0004217083186480771\n",
            "649/1000, error_single=0.003757840691798306 , error_batch=0.00042169650446731113\n",
            "650/1000, error_single=0.0037575982099146317 , error_batch=0.0004216839395065204\n",
            "651/1000, error_single=0.003757562084822555 , error_batch=0.00042167030476139897\n",
            "652/1000, error_single=0.003757320137878428 , error_batch=0.000421660501122801\n",
            "653/1000, error_single=0.0037572931400102526 , error_batch=0.0004216451010445107\n",
            "654/1000, error_single=0.003757050592757702 , error_batch=0.000421637684868891\n",
            "655/1000, error_single=0.0037570326200054745 , error_batch=0.00042162043077200866\n",
            "656/1000, error_single=0.003756788316635718 , error_batch=0.00042161519376964114\n",
            "657/1000, error_single=0.003756779350989266 , error_batch=0.0004215958862579161\n",
            "658/1000, error_single=0.0037565320817441674 , error_batch=0.00042159274343526543\n",
            "659/1000, error_single=0.0037565321894842906 , error_batch=0.0004215710712107155\n",
            "660/1000, error_single=0.003756280654033045 , error_batch=0.0004215700279374777\n",
            "661/1000, error_single=0.003756289987836236 , error_batch=0.0004215455538025968\n",
            "662/1000, error_single=0.003756032752647936 , error_batch=0.000421546690354157\n",
            "663/1000, error_single=0.0037560515555468926 , error_batch=0.00042151881421483966\n",
            "664/1000, error_single=0.003755787001670628 , error_batch=0.0004215222748522078\n",
            "665/1000, error_single=0.0037558156128045268 , error_batch=0.00042149016896278854\n",
            "666/1000, error_single=0.0037555418690842983 , error_batch=0.00042149615320547006\n",
            "667/1000, error_single=0.003755580731059555 , error_batch=0.00042145864912338714\n",
            "668/1000, error_single=0.0037552955855278576 , error_batch=0.00042146739484872904\n",
            "669/1000, error_single=0.003755345252902436 , error_batch=0.0004214227826811417\n",
            "670/1000, error_single=0.0037550460313110134 , error_batch=0.000421434520281901\n",
            "671/1000, error_single=0.0037551071790158934 , error_batch=0.0004213801709556035\n",
            "672/1000, error_single=0.0037547905730590486 , error_batch=0.0004213949881045638\n",
            "673/1000, error_single=0.003754864002053083 , error_batch=0.000421326584079798\n",
            "674/1000, error_single=0.00375452581868106 , error_batch=0.000421344010580371\n",
            "675/1000, error_single=0.0037546124528615647 , error_batch=0.0004212538017474739\n",
            "676/1000, error_single=0.0037542472359015466 , error_batch=0.000421271423817365\n",
            "677/1000, error_single=0.0037543480971048092 , error_batch=0.0004211436548325944\n",
            "678/1000, error_single=0.0037539485342508463 , error_batch=0.0004211517534096881\n",
            "679/1000, error_single=0.003754064665897424 , error_batch=0.0004209479687552359\n",
            "680/1000, error_single=0.003753620618083695 , error_batch=0.0004209031810448087\n",
            "681/1000, error_single=0.0037537528894745443 , error_batch=0.00042049907300079536\n",
            "682/1000, error_single=0.003753249718304235 , error_batch=0.0004201398403385633\n",
            "683/1000, error_single=0.0037533983448043524 , error_batch=0.0004189002845581333\n",
            "684/1000, error_single=0.0037528138446549643 , error_batch=0.0004156586185460694\n",
            "685/1000, error_single=0.003752977197163142 , error_batch=0.00040914410388037453\n",
            "686/1000, error_single=0.0037522755129865875 , error_batch=0.00040903036591676553\n",
            "687/1000, error_single=0.0037524470099758217 , error_batch=0.0004088622624012623\n",
            "688/1000, error_single=0.003751565316226271 , error_batch=0.00040888091812943427\n",
            "689/1000, error_single=0.003751724556526678 , error_batch=0.0004086879275871883\n",
            "690/1000, error_single=0.00375053975756516 , error_batch=0.00040877826778821234\n",
            "691/1000, error_single=0.0037506235205835114 , error_batch=0.00040858983992311094\n",
            "692/1000, error_single=0.0037488522196106357 , error_batch=0.00040869309484023366\n",
            "693/1000, error_single=0.003748637715838646 , error_batch=0.0004085251292631166\n",
            "694/1000, error_single=0.003745442164958241 , error_batch=0.00040863563081452444\n",
            "695/1000, error_single=0.0037438940819919274 , error_batch=0.0004084827721083839\n",
            "696/1000, error_single=0.003735511310606969 , error_batch=0.00040859026648107816\n",
            "697/1000, error_single=0.003724673129995079 , error_batch=0.00040845026164211036\n",
            "698/1000, error_single=0.0036837480431089593 , error_batch=0.0004085531349438465\n",
            "699/1000, error_single=0.0036456099637727966 , error_batch=0.000408423425905056\n",
            "700/1000, error_single=0.003629322852580683 , error_batch=0.00040852143165539005\n",
            "701/1000, error_single=0.003633674249132222 , error_batch=0.0004084000684694329\n",
            "702/1000, error_single=0.003628775510131732 , error_batch=0.000408493536204732\n",
            "703/1000, error_single=0.00363043489775034 , error_batch=0.0004083790412259128\n",
            "704/1000, error_single=0.0036267406552120147 , error_batch=0.0004084684145817536\n",
            "705/1000, error_single=0.003627388311635255 , error_batch=0.00040835967007807155\n",
            "706/1000, error_single=0.0036253571447891334 , error_batch=0.0004084453890383745\n",
            "707/1000, error_single=0.0036255690664075972 , error_batch=0.0004083415297510614\n",
            "708/1000, error_single=0.003624480017236729 , error_batch=0.00040842399775530735\n",
            "709/1000, error_single=0.0036246617371821547 , error_batch=0.0004083243359691679\n",
            "710/1000, error_single=0.0036239562799674414 , error_batch=0.00040840391472216986\n",
            "711/1000, error_single=0.0036241055596369686 , error_batch=0.0004083078899158508\n",
            "712/1000, error_single=0.0036235609545864416 , error_batch=0.00040838490118348523\n",
            "713/1000, error_single=0.0036236634200797293 , error_batch=0.0004082920466473124\n",
            "714/1000, error_single=0.003623219305461641 , error_batch=0.00040836677611081994\n",
            "715/1000, error_single=0.0036232852418476044 , error_batch=0.0004082766962238869\n",
            "716/1000, error_single=0.003622919399710829 , error_batch=0.00040834939762920204\n",
            "717/1000, error_single=0.00362295853966217 , error_batch=0.0004082617519137423\n",
            "718/1000, error_single=0.0036226549429368817 , error_batch=0.0004083326510102136\n",
            "719/1000, error_single=0.003622673222037761 , error_batch=0.00040824714256216496\n",
            "720/1000, error_single=0.0036224187672900753 , error_batch=0.0004083164406621067\n",
            "721/1000, error_single=0.0036224199775670876 , error_batch=0.00040823280748178106\n",
            "722/1000, error_single=0.0036222044228790386 , error_batch=0.0004083006846027377\n",
            "723/1000, error_single=0.0036221913984477933 , error_batch=0.0004082186928953503\n",
            "724/1000, error_single=0.003622006989632544 , error_batch=0.00040828531049829167\n",
            "725/1000, error_single=0.003621982074216283 , error_batch=0.0004082047493394452\n",
            "726/1000, error_single=0.0036218229788374913 , error_batch=0.00040827025269540585\n",
            "727/1000, error_single=0.0036217881640282475 , error_batch=0.00040819092965378983\n",
            "728/1000, error_single=0.0036216499577897358 , error_batch=0.0004082554498752238\n",
            "729/1000, error_single=0.003621606922520272 , error_batch=0.0004081771873062239\n",
            "730/1000, error_single=0.003621486199351803 , error_batch=0.0004082408430750348\n",
            "731/1000, error_single=0.003621436336131935 , error_batch=0.00040816347487396303\n",
            "732/1000, error_single=0.0036213304316224477 , error_batch=0.0004082263738891215\n",
            "733/1000, error_single=0.0036212748792359716 , error_batch=0.00040814974253782654\n",
            "734/1000, error_single=0.003621181677822224 , error_batch=0.00040821198269289755\n",
            "735/1000, error_single=0.0036211213589269183 , error_batch=0.0004081359364575649\n",
            "736/1000, error_single=0.0036210391584036686 , error_batch=0.0004081976067417251\n",
            "737/1000, error_single=0.0036209748169527384 , error_batch=0.0004081219968871386\n",
            "738/1000, error_single=0.0036209022314786037 , error_batch=0.00040818317798026345\n",
            "739/1000, error_single=0.0036208344664451038 , error_batch=0.0004081078558576296\n",
            "740/1000, error_single=0.0036207703556670546 , error_batch=0.0004081686203565706\n",
            "741/1000, error_single=0.0036206996496013174 , error_batch=0.00040809343419605996\n",
            "742/1000, error_single=0.0036206430659127212 , error_batch=0.0004081538463578048\n",
            "743/1000, error_single=0.003620569808226464 , error_batch=0.00040807863754705473\n",
            "744/1000, error_single=0.003620519956934565 , error_batch=0.00040813875235173923\n",
            "745/1000, error_single=0.0036204444624745305 , error_batch=0.00040806335089535434\n",
            "746/1000, error_single=0.0036204006713576216 , error_batch=0.00040812321209380637\n",
            "747/1000, error_single=0.0036203231950526025 , error_batch=0.00040804743080309814\n",
            "748/1000, error_single=0.003620284890858276 , error_batch=0.0004081070673740893\n",
            "749/1000, error_single=0.003620205639215525 , error_batch=0.000408030694086896\n",
            "750/1000, error_single=0.003620172329350023 , error_batch=0.0004080901140996078\n",
            "751/1000, error_single=0.003620091469474367 , error_batch=0.0004080129007909747\n",
            "752/1000, error_single=0.0036200627276081563 , error_batch=0.00040807208086775557\n",
            "753/1000, error_single=0.003619980394292214 , error_batch=0.0004079937277080427\n",
            "754/1000, error_single=0.003619955848941245 , error_batch=0.0004080525947270218\n",
            "755/1000, error_single=0.003619872150258156 , error_batch=0.00040797272559647867\n",
            "756/1000, error_single=0.0036198514756410178 , error_batch=0.0004080311241002289\n",
            "757/1000, error_single=0.0036197664973731157 , error_batch=0.0004079492469096087\n",
            "758/1000, error_single=0.0036197494060203486 , error_batch=0.000408006878832058\n",
            "759/1000, error_single=0.0036196632151789887 , error_batch=0.000407922317075323\n",
            "760/1000, error_single=0.003619649451900519 , error_batch=0.0004079786245499754\n",
            "761/1000, error_single=0.00361956209953168 , error_batch=0.00040789038999058925\n",
            "762/1000, error_single=0.0036195514364439564 , error_batch=0.0004079443121713701\n",
            "763/1000, error_single=0.0036194629598679073 , error_batch=0.00040785084477090413\n",
            "764/1000, error_single=0.003619455192253782 , error_batch=0.00040790026850904534\n",
            "765/1000, error_single=0.003619365616851708 , error_batch=0.00040779883733470983\n",
            "766/1000, error_single=0.0036193605596784983 , error_batch=0.00040783920720297554\n",
            "767/1000, error_single=0.003619269900312084 , error_batch=0.0004077242913407673\n",
            "768/1000, error_single=0.0036192673852730585 , error_batch=0.0004077444900458118\n",
            "769/1000, error_single=0.0036191756474025097 , error_batch=0.00040760230846695697\n",
            "770/1000, error_single=0.0036191755203763363 , error_batch=0.0004075692083739971\n",
            "771/1000, error_single=0.0036190827009264163 , error_batch=0.00040735182725753686\n",
            "772/1000, error_single=0.0036190848197715886 , error_batch=0.00040712479550293\n",
            "773/1000, error_single=0.0036189909077829615 , error_batch=0.000406531226804865\n",
            "774/1000, error_single=0.003618995140400894 , error_batch=0.000404857728165627\n",
            "775/1000, error_single=0.0036189001174941884 , error_batch=0.00039841497714857574\n",
            "776/1000, error_single=0.0036189063401077834 , error_batch=0.0003913464278383459\n",
            "777/1000, error_single=0.0036188101807802494 , error_batch=0.0003879087966328678\n",
            "778/1000, error_single=0.0036188182763844767 , error_batch=0.00038768796793220824\n",
            "779/1000, error_single=0.0036187209481522015 , error_batch=0.0003875670386787903\n",
            "780/1000, error_single=0.003618730805101529 , error_batch=0.0003879694561351785\n",
            "781/1000, error_single=0.0036186322684949347 , error_batch=0.00038805882621493847\n",
            "782/1000, error_single=0.0036186437791983312 , error_batch=0.0003884884307051831\n",
            "783/1000, error_single=0.0036185439876135804 , error_batch=0.0003882322856943014\n",
            "784/1000, error_single=0.0036185570473137797 , error_batch=0.0003885054240392629\n",
            "785/1000, error_single=0.003618455946718261 , error_batch=0.0003881759169728546\n",
            "786/1000, error_single=0.003618470452336562 , error_batch=0.0003884132110408897\n",
            "787/1000, error_single=0.0036183679808221582 , error_batch=0.0003881250566974185\n",
            "788/1000, error_single=0.003618383829855162 , error_batch=0.0003883311732700021\n",
            "789/1000, error_single=0.003618279917028905 , error_batch=0.0003880742980372164\n",
            "790/1000, error_single=0.0036182970064890046 , error_batch=0.00038825379313675134\n",
            "791/1000, error_single=0.0036181915726861123 , error_batch=0.00038801819366681556\n",
            "792/1000, error_single=0.0036182097980841797 , error_batch=0.0003881732912286721\n",
            "793/1000, error_single=0.003618102753384224 , error_batch=0.00038795087196937005\n",
            "794/1000, error_single=0.0036181220077614795 , error_batch=0.0003880808375504913\n",
            "795/1000, error_single=0.003618013250783929 , error_batch=0.0003878632587381882\n",
            "796/1000, error_single=0.003618033423811455 , error_batch=0.00038796249066834054\n",
            "797/1000, error_single=0.0036179228402627196 , error_batch=0.00038773794636284\n",
            "798/1000, error_single=0.0036179438174434586 , error_batch=0.0003877906030788115\n",
            "799/1000, error_single=0.0036178312783837568 , error_batch=0.0003875359141045602\n",
            "800/1000, error_single=0.0036178529404140626 , error_batch=0.00038749896727100777\n",
            "801/1000, error_single=0.0036177383002105167 , error_batch=0.00038715359708839885\n",
            "802/1000, error_single=0.0036177605225905587 , error_batch=0.00038689705549747167\n",
            "803/1000, error_single=0.0036176436165233244 , error_batch=0.00038625001239455834\n",
            "804/1000, error_single=0.003617666269550079 , error_batch=0.00038539455634902767\n",
            "805/1000, error_single=0.003617546911043976 , error_batch=0.0003840015450904818\n",
            "806/1000, error_single=0.0036175698603829747 , error_batch=0.0003836051949656847\n",
            "807/1000, error_single=0.0036174478378510843 , error_batch=0.00038345311954732757\n",
            "808/1000, error_single=0.0036174709459686886 , error_batch=0.00038348280127124346\n",
            "809/1000, error_single=0.0036173460192821956 , error_batch=0.000383380684844734\n",
            "810/1000, error_single=0.003617369148136055 , error_batch=0.00038344289483739635\n",
            "811/1000, error_single=0.0036172410447846176 , error_batch=0.0003833165486416568\n",
            "812/1000, error_single=0.00361726406032235 , error_batch=0.00038340184177890153\n",
            "813/1000, error_single=0.003617132471413013 , error_batch=0.0003832582491379252\n",
            "814/1000, error_single=0.003617155250622122 , error_batch=0.0003833605614132974\n",
            "815/1000, error_single=0.0036170198269991492 , error_batch=0.0003832160568940695\n",
            "816/1000, error_single=0.0036170422684810447 , error_batch=0.00038332384033550894\n",
            "817/1000, error_single=0.0036169026174555203 , error_batch=0.0003831836333986744\n",
            "818/1000, error_single=0.003616924656740714 , error_batch=0.00038329361947289685\n",
            "819/1000, error_single=0.003616780340222385 , error_batch=0.0003831587984713775\n",
            "820/1000, error_single=0.003616801971246459 , error_batch=0.0003832689197815908\n",
            "821/1000, error_single=0.003616652506494772 , error_batch=0.00038313926869576416\n",
            "822/1000, error_single=0.0036166738106944442 , error_batch=0.0003832481260343325\n",
            "823/1000, error_single=0.0036165186754566333 , error_batch=0.00038312327599281966\n",
            "824/1000, error_single=0.0036165398596024706 , error_batch=0.00038323010161628486\n",
            "825/1000, error_single=0.003616378504046328 , error_batch=0.00038310964810073483\n",
            "826/1000, error_single=0.0036163999468435755 , error_batch=0.0003832139657065425\n",
            "827/1000, error_single=0.0036162318152863243 , error_batch=0.0003830975897395218\n",
            "828/1000, error_single=0.0036162541204460166 , error_batch=0.0003831991399135609\n",
            "829/1000, error_single=0.0036160786861327444 , error_batch=0.00038308658687930615\n",
            "830/1000, error_single=0.0036161027354996455 , error_batch=0.00038318524186969064\n",
            "831/1000, error_single=0.003615919551074457 , error_batch=0.00038307630994326635\n",
            "832/1000, error_single=0.0036159465452544805 , error_batch=0.0003831720268520866\n",
            "833/1000, error_single=0.0036157553093801005 , error_batch=0.00038306655143088245\n",
            "834/1000, error_single=0.0036157867759020945 , error_batch=0.0003831593388811107\n",
            "835/1000, error_single=0.0036155874120718584 , error_batch=0.00038305718198415194\n",
            "836/1000, error_single=0.0036156251552073655 , error_batch=0.00038314707813580834\n",
            "837/1000, error_single=0.003615417892224189 , error_batch=0.0003830481211673387\n",
            "838/1000, error_single=0.0036154638595411273 , error_batch=0.000383135179251077\n",
            "839/1000, error_single=0.0036152492961195465 , error_batch=0.0003830393184555453\n",
            "840/1000, error_single=0.00361530535129559 , error_batch=0.0003831235975180239\n",
            "841/1000, error_single=0.003615084483590826 , error_batch=0.00038303074125725737\n",
            "842/1000, error_single=0.003615152105987897 , error_batch=0.00038311230038359356\n",
            "843/1000, error_single=0.0036149263011467773 , error_batch=0.0003830223675954954\n",
            "844/1000, error_single=0.0036150062724015952 , error_batch=0.000383101262380527\n",
            "845/1000, error_single=0.0036147771850904347 , error_batch=0.00038301418175930226\n",
            "846/1000, error_single=0.003614869350492573 , error_batch=0.00038309046218830276\n",
            "847/1000, error_single=0.0036146387978957615 , error_batch=0.00038300617178147086\n",
            "848/1000, error_single=0.0036147419821418196 , error_batch=0.0003830798809686767\n",
            "849/1000, error_single=0.0036145118062620315 , error_batch=0.0003829983280022063\n",
            "850/1000, error_single=0.003614623914415947 , error_batch=0.0003830695014351563\n",
            "851/1000, error_single=0.0036143958613403452 , error_batch=0.0003829906422600151\n",
            "852/1000, error_single=0.003614514130672654 , error_batch=0.0003830593073293414\n",
            "853/1000, error_single=0.003614289766227402 , error_batch=0.00038298310743653844\n",
            "854/1000, error_single=0.003614411089535689 , error_batch=0.0003830492831137746\n",
            "855/1000, error_single=0.0036141917569503367 , error_batch=0.00038297571719809337\n",
            "856/1000, error_single=0.0036143129924500208 , error_batch=0.000383039413774594\n",
            "857/1000, error_single=0.003614099806530943 , error_batch=0.0003829684658462023\n",
            "858/1000, error_single=0.003614218015149826 , error_batch=0.0003830296846761977\n",
            "859/1000, error_single=0.0036140118810959877 , error_batch=0.00038296134822945484\n",
            "860/1000, error_single=0.003614124467419338 , error_batch=0.0003830200814374841\n",
            "861/1000, error_single=0.00361392611082319 , error_batch=0.0003829543596913518\n",
            "862/1000, error_single=0.0036140308724924475 , error_batch=0.0003830105898138083\n",
            "863/1000, error_single=0.003613840869603232 , error_batch=0.00038294749604089246\n",
            "864/1000, error_single=0.003613935975963596 , error_batch=0.00038300119557609503\n",
            "865/1000, error_single=0.0036137547781897473 , error_batch=0.0003829407535391111\n",
            "866/1000, error_single=0.00361383870369358 , error_batch=0.0003829918843818276\n",
            "867/1000, error_single=0.0036136666550582093 , error_batch=0.00038293412889822437\n",
            "868/1000, error_single=0.003613738090032007 , error_batch=0.00038298264163378465\n",
            "869/1000, error_single=0.003613575439044284 , error_batch=0.00038292761929197765\n",
            "870/1000, error_single=0.003613633193699879 , error_batch=0.00038297345232237654\n",
            "871/1000, error_single=0.0036134801015745956 , error_batch=0.00038292122237696644\n",
            "872/1000, error_single=0.0036135230116018336 , error_batch=0.0003829643008467422\n",
            "873/1000, error_single=0.003613379557748673 , error_batch=0.00038291493632559034\n",
            "874/1000, error_single=0.0036134063932936854 , error_batch=0.00038295517080857294\n",
            "875/1000, error_single=0.003613272577468548 , error_batch=0.00038290875987208447\n",
            "876/1000, error_single=0.003613281952385638 , error_batch=0.00038294604477097854\n",
            "877/1000, error_single=0.003613157691380781 , error_batch=0.0003829026923739033\n",
            "878/1000, error_single=0.003613147966026831 , error_batch=0.00038293690397244687\n",
            "879/1000, error_single=0.003613033081273146 , error_batch=0.00038289673389171837\n",
            "880/1000, error_single=0.0036130022489290143 , error_batch=0.0003829277279829428\n",
            "881/1000, error_single=0.0036128964394748016 , error_batch=0.00038289088529252607\n",
            "882/1000, error_single=0.0036128419825706974 , error_batch=0.0003829184942850697\n",
            "883/1000, error_single=0.0036127447748333674 , error_batch=0.00038288514838196364\n",
            "884/1000, error_single=0.0036126634710411843 , error_batch=0.0003829091777575768\n",
            "885/1000, error_single=0.003612574131286612 , error_batch=0.00038287952607410526\n",
            "886/1000, error_single=0.0036124617790541423 , error_batch=0.00038289975003062313\n",
            "887/1000, error_single=0.0036123791646382976 , error_batch=0.00038287402260996154\n",
            "888/1000, error_single=0.003612230179193273 , error_batch=0.0003828901786711247\n",
            "889/1000, error_single=0.003612152486257558 , error_batch=0.00038286864384003805\n",
            "890/1000, error_single=0.0036119592836191543 , error_batch=0.0003828804261406495\n",
            "891/1000, error_single=0.003611883614478969 , error_batch=0.00038286339759214584\n",
            "892/1000, error_single=0.0036116356390562183 , error_batch=0.0003828704484453563\n",
            "893/1000, error_single=0.0036115572468548894 , error_batch=0.0003828582941540287\n",
            "894/1000, error_single=0.003611239380563147 , error_batch=0.00038286019336358014\n",
            "895/1000, error_single=0.0036111503231866546 , error_batch=0.0003828533469125649\n",
            "896/1000, error_single=0.00361074018598782 , error_batch=0.00038284959808592475\n",
            "897/1000, error_single=0.0036106268889471967 , error_batch=0.0003828485732093174\n",
            "898/1000, error_single=0.0036100900998478538 , error_batch=0.00038283858602519276\n",
            "899/1000, error_single=0.0036099289612141327 , error_batch=0.000382843995499229\n",
            "900/1000, error_single=0.0036092106428034384 , error_batch=0.0003828270624326322\n",
            "901/1000, error_single=0.003608960639991646 , error_batch=0.0003828396429404874\n",
            "902/1000, error_single=0.0036079706009616375 , error_batch=0.0003828149082642575\n",
            "903/1000, error_single=0.0036075646302680454 , error_batch=0.00038283555360754554\n",
            "904/1000, error_single=0.00360615702300691 , error_batch=0.0003828019714258419\n",
            "905/1000, error_single=0.003605514695731731 , error_batch=0.00038283177762028493\n",
            "906/1000, error_single=0.003603501083422098 , error_batch=0.00038278805399521483\n",
            "907/1000, error_single=0.0036026729781297286 , error_batch=0.0003828283816447309\n",
            "908/1000, error_single=0.0036001001227106495 , error_batch=0.0003827728931010041\n",
            "909/1000, error_single=0.0035996323475556906 , error_batch=0.00038282545548641914\n",
            "910/1000, error_single=0.003597488787527178 , error_batch=0.0003827561314844322\n",
            "911/1000, error_single=0.0035977419022307252 , error_batch=0.00038282312193876764\n",
            "912/1000, error_single=0.0035969011113755607 , error_batch=0.00038273727067982997\n",
            "913/1000, error_single=0.003597060250719322 , error_batch=0.000382821551787868\n",
            "914/1000, error_single=0.0035970106721106916 , error_batch=0.00038271559369767246\n",
            "915/1000, error_single=0.003596879151093326 , error_batch=0.0003828209871041264\n",
            "916/1000, error_single=0.003597111420047671 , error_batch=0.00038269003160311366\n",
            "917/1000, error_single=0.0035968361269222045 , error_batch=0.00038282177789447365\n",
            "918/1000, error_single=0.0035971597492472987 , error_batch=0.00038265892096649943\n",
            "919/1000, error_single=0.0035968172164926393 , error_batch=0.00038282443968956403\n",
            "920/1000, error_single=0.003597174958240249 , error_batch=0.0003826195344569872\n",
            "921/1000, error_single=0.0035967977801864863 , error_batch=0.0003828297396845774\n",
            "922/1000, error_single=0.0035971714953682405 , error_batch=0.00038256710033565813\n",
            "923/1000, error_single=0.0035967745786535236 , error_batch=0.00038283879684326936\n",
            "924/1000, error_single=0.0035971573651854137 , error_batch=0.0003824925510459761\n",
            "925/1000, error_single=0.003596747835330484 , error_batch=0.0003828530161931787\n",
            "926/1000, error_single=0.0035971366204228185 , error_batch=0.00038237670227809134\n",
            "927/1000, error_single=0.003596718162187078 , error_batch=0.0003828725528362456\n",
            "928/1000, error_single=0.003597111459232661 , error_batch=0.000382172838861868\n",
            "929/1000, error_single=0.0035966862306574163 , error_batch=0.0003828830202606384\n",
            "930/1000, error_single=0.0035970832705901 , error_batch=0.0003817468549761559\n",
            "931/1000, error_single=0.003596652698794897 , error_batch=0.0003827243168446696\n",
            "932/1000, error_single=0.0035970530310747875 , error_batch=0.00038071967415215116\n",
            "933/1000, error_single=0.0035966181407661533 , error_batch=0.00038101224401182183\n",
            "934/1000, error_single=0.003597021443692482 , error_batch=0.0003676649663628466\n",
            "935/1000, error_single=0.0035965830072149573 , error_batch=0.0003625528157197961\n",
            "936/1000, error_single=0.0035969890024277456 , error_batch=0.00036163062732414694\n",
            "937/1000, error_single=0.0035965476219932384 , error_batch=0.0003618719641109926\n",
            "938/1000, error_single=0.00359695604023227 , error_batch=0.00036166932879750193\n",
            "939/1000, error_single=0.0035965122003779075 , error_batch=0.0003619972359216125\n",
            "940/1000, error_single=0.003596922770845318 , error_batch=0.00035902931684570594\n",
            "941/1000, error_single=0.0035964768741622087 , error_batch=0.00034848353605940906\n",
            "942/1000, error_single=0.003596889323675451 , error_batch=0.00034772242741113477\n",
            "943/1000, error_single=0.0035964417153136826 , error_batch=0.0003474707142096093\n",
            "944/1000, error_single=0.003596855770807879 , error_batch=0.00034726397766421944\n",
            "945/1000, error_single=0.0035964067550378906 , error_batch=0.0003471200910645285\n",
            "946/1000, error_single=0.0035968221466583976 , error_batch=0.000347010575274236\n",
            "947/1000, error_single=0.003596371997873346 , error_batch=0.0003469091144119662\n",
            "948/1000, error_single=0.00359678846161886 , error_batch=0.0003468387669351869\n",
            "949/1000, error_single=0.0035963374315614444 , error_batch=0.0003467643259438102\n",
            "950/1000, error_single=0.0035967547111884278 , error_batch=0.00034671244757223307\n",
            "951/1000, error_single=0.003596303033693481 , error_batch=0.00034665608377588736\n",
            "952/1000, error_single=0.003596720881891653 , error_batch=0.0003466139442960304\n",
            "953/1000, error_single=0.003596268776042502 , error_batch=0.0003465693737197103\n",
            "954/1000, error_single=0.0035966869549921773 , error_batch=0.0003465331878869828\n",
            "955/1000, error_single=0.0035962346272930125 , error_batch=0.0003464965673927586\n",
            "956/1000, error_single=0.0035966529087336327 , error_batch=0.00034646479032409013\n",
            "957/1000, error_single=0.003596200554690118 , error_batch=0.00034643392684727986\n",
            "958/1000, error_single=0.0035966187196174557 , error_batch=0.0003464059128028356\n",
            "959/1000, error_single=0.0035961665249733487 , error_batch=0.00034637946721783166\n",
            "960/1000, error_single=0.003596584363062111 , error_batch=0.0003463547760623454\n",
            "961/1000, error_single=0.003596132504844351 , error_batch=0.0003463317828679307\n",
            "962/1000, error_single=0.003596549813671571 , error_batch=0.00034630992599138784\n",
            "963/1000, error_single=0.0035960984611347916 , error_batch=0.00034628958439489896\n",
            "964/1000, error_single=0.0035965150452610265 , error_batch=0.0003462700080626404\n",
            "965/1000, error_single=0.003596064360783346 , error_batch=0.00034625163444524764\n",
            "966/1000, error_single=0.0035964800307333356 , error_batch=0.0003462337901019779\n",
            "967/1000, error_single=0.0035960301706920795 , error_batch=0.00034621682522396354\n",
            "968/1000, error_single=0.0035964447418642283 , error_batch=0.00034620023229729686\n",
            "969/1000, error_single=0.0035959958575059684 , error_batch=0.0003461842416447124\n",
            "970/1000, error_single=0.003596409149030571 , error_batch=0.000346168510960499\n",
            "971/1000, error_single=0.0035959613873425764 , error_batch=0.0003461531651490325\n",
            "972/1000, error_single=0.00359637322090072 , error_batch=0.00034613799107044673\n",
            "973/1000, error_single=0.0035959267254867555 , error_batch=0.00034612303664501834\n",
            "974/1000, error_single=0.0035963369240960335 , error_batch=0.00034610817612242976\n",
            "975/1000, error_single=0.0035958918360579997 , error_batch=0.00034609340794934516\n",
            "976/1000, error_single=0.003596300222826073 , error_batch=0.0003460786587791587\n",
            "977/1000, error_single=0.0035958566816527487 , error_batch=0.0003460638986773831\n",
            "978/1000, error_single=0.0035962630784956615 , error_batch=0.00034604908158379996\n",
            "979/1000, error_single=0.003595821222960237 , error_batch=0.00034603416298932283\n",
            "980/1000, error_single=0.0035962254492789792 , error_batch=0.0003460191077671157\n",
            "981/1000, error_single=0.003595785418348139 , error_batch=0.00034600386445687815\n",
            "982/1000, error_single=0.0035961872896536308 , error_batch=0.0003459883988895596\n",
            "983/1000, error_single=0.003595749223411731 , error_batch=0.00034597265572660203\n",
            "984/1000, error_single=0.0035961485498854436 , error_batch=0.00034595659579501106\n",
            "985/1000, error_single=0.003595712590478743 , error_batch=0.0003459401598661454\n",
            "986/1000, error_single=0.0035961091754532167 , error_batch=0.0003459232999148252\n",
            "987/1000, error_single=0.0035956754680600295 , error_batch=0.000345905950762817\n",
            "988/1000, error_single=0.003596069106400208 , error_batch=0.00034588805239765504\n",
            "989/1000, error_single=0.0035956378002342058 , error_batch=0.0003458695301537579\n",
            "990/1000, error_single=0.0035960282765972558 , error_batch=0.00034585030858972564\n",
            "991/1000, error_single=0.003595599525952132 , error_batch=0.0003458302986885581\n",
            "992/1000, error_single=0.0035959866128991145 , error_batch=0.0003458094050362951\n",
            "993/1000, error_single=0.003595560578244063 , error_batch=0.00034578751788164947\n",
            "994/1000, error_single=0.003595944034172608 , error_batch=0.0003457645154896793\n",
            "995/1000, error_single=0.0035955208833092895 , error_batch=0.0003457402590262885\n",
            "996/1000, error_single=0.0035959004501706134 , error_batch=0.00034571459162977957\n",
            "997/1000, error_single=0.003595480359463407 , error_batch=0.00034568733455399395\n",
            "998/1000, error_single=0.003595855760220614 , error_batch=0.00034565828414937015\n",
            "999/1000, error_single=0.0035954389159133333 , error_batch=0.000345627208419576\n",
            "1000/1000, error_single=0.0035958098516900116 , error_batch=0.00034559384317709607\n"
          ]
        }
      ],
      "source": [
        "batch_size=10\n",
        "x_train, y_train, x_test, y_test = load_data(1000)\n",
        "#output=forward_batch(model, x_train[0:batch_size], batch_size)\n",
        "#output.shape\n",
        "#train_batch(model, mse, x_train, y_train, epochs=30, batch_size=batch_size)\n",
        "#train(model_1, mse, x_train, y_train, epochs=3)\n",
        "#train(model_2, mse, x_train, y_train, epochs=3)\n",
        "           \n",
        "train_debug(model_single, model_batch, mse, x_train, y_train, epochs=1000,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('error on test set:', test(model_single, mse, x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOyIiq9o7cRP",
        "outputId": "e86d4dc4-2600-4fc2-8b40-327ae3cdcbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error on test set: 0.02971994954095478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('error on test set:', test(model_batch, mse, x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0WsRz_j_Xfe",
        "outputId": "cf907c90-2d9d-43ea-8b3e-ebc41a5ff826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error on test set: 0.031060595854633142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RL_eRll_bZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GxZtifJHYut1pVO4RsIaDd_Whm64XcQ-",
      "authorship_tag": "ABX9TyPyLjZveTnBBW31+pSb0chA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}